% easychair.tex,v 3.5 2017/03/15

\documentclass{easychair}
%\documentclass[EPiC]{easychair}
%\documentclass[EPiCempty]{easychair}
%\documentclass[debug]{easychair}
%\documentclass[verbose]{easychair}
%\documentclass[notimes]{easychair}
%\documentclass[withtimes]{easychair}
%\documentclass[a4paper]{easychair}
%\documentclass[letterpaper]{easychair}

\usepackage{doc}
\usepackage{fullpage}
\usepackage{latexsym}
\usepackage{verbatim}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{stackengine}
\usepackage{scalerel}
\usepackage{code,proof,amsthm,amssymb, amsmath}
\usepackage{mathpartir}
\usepackage{turnstile}
\usepackage{fancyvrb}
\usepackage{stmaryrd}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{booktabs}
\usepackage{adjustbox}
\usepackage{color}
\usepackage{wrapfig}
\usetikzlibrary{positioning} 

\allowdisplaybreaks

\input{../generic-defns}
\input{../syn-defns}
\input{../../pfpl/fun-defns}
\input{../../pfpl/pcf-defns}
\input{../../pfpl/prod-defns}
\input{../../pfpl/sum-defns}
\input{../../pfpl/icoi-defns}
\input{../../pfpl/t-defns}


% use this if you have a long article and want to create an index
% \usepackage{makeidx}

% In order to save space or manage large tables or figures in a
% landcape-like text, you can use the rotating and pdflscape
% packages. Uncomment the desired from the below.
%
% \usepackage{rotating}
% \usepackage{pdflscape}

% Some of our commands for this guide.
%
\newcommand{\easychair}{\textsf{easychair}}
\newcommand{\miktex}{MiK{\TeX}}
\newcommand{\texniccenter}{{\TeX}nicCenter}
\newcommand{\makefile}{\texttt{Makefile}}
\newcommand{\latexeditor}{LEd}

\newcommand{\myname}{Andrew Carnegie}
\newcommand{\myandrewid}{andrew}
\newcommand{\hwnumber}{1}
% =========================================================================== %

\newtheorem{theorem}{Theorem}

\newcommand{\ms}[1]{\ensuremath{\mathsf{#1}}}
\newcommand{\irl}[1]{\mathtt{#1}}
\newcounter{rule}
\setcounter{rule}{0}
\newcommand{\rn}
  {\addtocounter{rule}{1}(\arabic{rule})}	

\newcounter{infercount}
\setcounter{infercount}{1}
\newcommand{\infern}[2]{\inferrule{#1}{#2}(\text{S}_{\arabic{infercount}}\stepcounter{infercount})}
\newcommand*\ts[2]{%
  \,\scalebox{1}[0.5]{$\sststile[ss]{\textstyle#1}{\textstyle#2}$}\,
}
\newcommand{\inferr}[2]{\inferrule{#2}{#1}}
\newcommand{\inferrr}[3]{\inferrule[#1]{#2}{#3}}
\newcommand{\paircaseabt}[4]{\irl{match_P}(#2,#3.#4)}
\newcommand{\paircasecst}[4]{\irl{match} \; #1\; \{(#2;#3) \hookrightarrow #4\}}
\newcommand{\na}[1]{\mathsf{linear}(#1)}
\newcommand{\nr}[1]{\mathsf{no\_ref}(#1)}
\newcommand{\stable}[1]{\mathsf{stable}(#1)}
\newcommand{\set}[1]{\mathsf{set}(#1)}
\newcommand{\safe}[1]{\mathsf{safe}(#1)}
\newcommand{\dist}[1]{\mathsf{disjoint}(#1)}
\newcommand{\stack}[1]{\irl{stack}(#1)}
\newcommand{\denote}[1]{\llbracket#1\rrbracket}
\newcommand{\nil}{[]}
\newcommand{\cons}[2]{\pi(#1,#2)}
\newcommand{\sharecst}[4]{\irl{share}\;#1\;\irl{as}\;#2,#3\;\irl{in}\;#4}
\newcommand{\sharecpcst}[4]{\irl{share}\;#1\;\irl{as}\;#2,#3\;\irl{in}\;#4}
\newcommand{\shareabt}[4]{\irl{share}(#1;#2,#3.#4)}
\newcommand{\ssize}[2]{\left\Vert #2 \right\Vert_{#1}}
\newcommand{\card}[1]{card(#1)}
\newcommand{\val}[1]{\irl{val}(#1)}
\newcommand{\gc}[3]{\mathsf{gc}(#1,#2,#3)}
\newcommand{\wfc}[5]{\mathsf{linear}(#1,#2,#3,#4,#5)}
\newcommand{\veq}[4]{#3 \sim^{#1}_{#2} #4}
\newcommand{\ctxeq}[2]{(#1) \sim (#2)}
\newcommand{\oh}[1]{\oslash(#1)}
\newcommand{\fogc}{\ms{FO}^{gc}}
\newcommand{\jan}[1]{{\color{red} [\emph{Jan: #1}]}}
\newcommand{\yue}[1]{{\color{blue} [\emph{Yue: #1}]}}
\newcommand{\gcSem}{\ensuremath{\mathcal{E}_{\ms{gc}}}}
\newcommand{\copySem}{\ensuremath{\mathcal{E}_{\ms{copy}}}}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{attempt}[theorem]{Attempt}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
%\makeindex

%% Front Matter
%%
% Regular title as in the article class.
%
\title{Automatic Space Bound Analysis for Functional Programs with Garbage Collection}

% Authors are joined by \and. Their affiliations are given by \inst, which indexes
% into the list defined using \institute
%
\author{
Yue Niu
\and
Jan Hoffmann
}

% Institutes for affiliations are also joined by \and,
\institute{
  Carnegie Mellon University,
  Pittsburgh, PA, United States\\
  \email{\{yuen,jhoffmann\}@cs.cmu.edu}
 }

%  \authorrunning{} has to be set for the shorter version of the authors' names;
% otherwise a warning will be rendered in the running heads. When processed by
% EasyChair, this command is mandatory: a document without \authorrunning
% will be rejected by EasyChair

\authorrunning{Niu and Hoffmann}

% \titlerunning{} has to be set to either the main title or its shorter
% version for the running heads. When processed by
% EasyChair, this command is mandatory: a document without \titlerunning
% will be rejected by EasyChair
\titlerunning{The {\easychair} Class File}

\begin{document}

\maketitle

\begin{abstract}
  This article introduces a novel system for deriving upper bounds on
  the heap-space requirements of functional programs with garbage
  collection.
  %
  The space cost model is based on a perfect garbage collector that
  immediately deallocates memory cells when they become unreachable.
  %
  Heap-space bounds are derived using type-based automatic amortized
  resource analysis (AARA), a template-based technique that
  efficiently reduces bound inference to linear programming.
  %
	The first technical contribution of the work is a new operational cost
  semantics that models a perfect garbage collector.
  %
  The second technical contribution is an extension of AARA
  to take into account automatic deallocation. A key observation is
  that deallocation of a perfect collector can be modeled with
  destructive pattern matching if data structures are used in a linear
  way. However, the analysis uses destructive pattern matching to
  accurately model deallocation even if data is shared.
  The soundness of the extended AARA with respect to the new cost semantics 
	is proven in two parts via an intermediate linear cost semantics.
  %
  The analysis and the cost semantics have been implemented as an
  extension to Resource Aware ML (RaML). An experimental evaluation
  shows that the system is able to derive tight symbolic heap-space
  bounds for common algorithms. Often the bounds are asymptotic
  improvements over bounds that RaML derives without taking into
  account garbage collection.
\end{abstract}

% The table of contents below is added for your convenience. Please do not use
% the table of contents if you are preparing your paper for publication in the
% EPiC Series or Kalpa Publications series

\iffalse
\setcounter{tocdepth}{3}
{\small
\tableofcontents}
\fi

%\section{To mention}
%
%Processing in EasyChair - number of pages.
%
%Examples of how EasyChair processes papers. Caveats (replacement of EC
%class, errors).

%------------------------------------------------------------------------------
\section{Introduction}
\label{sect:introduction}
The memory footprint of a program is an important performance metric
that determines if a program can be safely executed on a given
system. Ideally, developers should describe or approximate the memory
footprint of programs as functions of the inputs. However, such memory
bounds are often difficult to derive and to prove sound.
%
To assist programmers with deriving memory bounds, the programming
language community has developed automatic and semi-automatic analysis
techniques~\cite{Jost03,Chin08,Albert07b}
%
These systems are often special cases of more general resource bound
analyses that are based on abstract
interpretation~\cite{GulwaniMC09,BlancHHK10,SinnZV14},
recurrence
solving~\cite{FloresH14,AlbertFR15,DannerLR15,KincaidBBR2017}, type
systems~\cite{Jost10,HoffmannW15,LagoG11,CicekBGGH16,OOPSLA:WWC17,DasHP18},
program logics~\cite{Atkey10,CarbonneauxHZ15,CarbonneauxHRS17,Radicek17}, proof
assistants~\cite{Nipkow15,ChargueraudP15}, and term
rewriting~\cite{AvanziniM13,NoschinskiEG13,FrohnNHBG16}.

This article introduces a novel type system for automatically deriving
upper bounds on the heap-space requirements of functional programs
with garbage collection (GC).
%
Due to the challenges of modeling and predicting garbage collection,
most existing techniques for automating and guiding the derivation of
bounds on the heap memory requirements assume manual memory management
or simply ignore deallocation in the
analysis~\cite{Jost03,Jost06,SimoesVFJH12,Chin05,Chin08,Albert07b}. As
a result, the derived bounds are not accurate when the underlying
system employs garbage collection. The only exceptions we are aware of
are the works by Albert et al.~\cite{Albert09,Albert13}, by Braberman
et al.~\cite{Braberman08}, and by Unnikrishnan et
al.~\cite{UnnikrishnanSL03,Unnikrishnan09}. They analyze the
heap-space usage of programs with GC in two steps. First, they make
the deallocation of GC explicit; for example with a static analysis
for estimating object lifetimes~\cite{Albert13} or with a program
translation~\cite{Unnikrishnan09}. Second, they extract and solve
recurrence relations to derive a bound. The difference of our work is
that our technique is based on a type system, which is proved sound
with respect to a formal cost semantics. Advantages of a type-based
approach include natural compositionality and the use of type
derivations as certificates for resource bounds.

We model the (highwater mark) memory
usage based on a perfect garbage collector that immediately
deallocates memory cells when they become unreachable. The bounds that
are derived with for this cost model are not only a good theoretical
measure of the space complexity of the program but also have practical
relevance. Consider a function $f : A \to B$ and assume we derived a
bound $b_f : \denote{A} \to \mathbb{N}$. In an execution of $f(a)$, we
can then keep track of the memory usage and start the garbage
collector whenever the bound $b_f(a)$ is reached. It is then
guaranteed that the evaluation will succeed using $b_f(a)$ heap-memory
cells.\footnote{We are not considering memory fragmentation, which
  can be avoided using a copying collector.} To improve performance,
it we could still trigger GC more often or allow memory use of more
than $b_f(a)$ cells.

\emph{The first technical contribution} of the work is a new
operational cost semantics that models a perfect garbage collector.
%
The cost semantics is a big-step (or natural) semantics that keeps
track of the reachable memory cells in the style Spoonhower et
al.~\cite{Spoonhower:2008:SPP:1411204.1411240} and
Minamide~\cite{DBLP:journals/entcs/Minamide99}. Operationally, this
cost is the highwater mark on the heap usage, or the maximum number of
cells used in the mutable store during evaluation, if we assume that
cells are only used if they are reachable from the reminder of the
computation. Our formalization of reachability is identical with the
concept that garbage collectors implement to decide if a cell can be
freed during evaluation. For simplicity, we assume that evaluation of
constructors allocates one fresh heap cell and that all other
operations do not allocate heap cells. However, the semantics can be
instantiated with more realistic cost metrics. A difference to
existing formulations of cost semantics with
GC~\cite{Spoonhower:2008:SPP:1411204.1411240,DBLP:journals/entcs/Minamide99}
is that we update the highwater mark when reachability changes at
inner notes of the derivation of the evaluation judgement instead of
leaves. Moreover, we use a \emph{freelist}, which represents the
cells available for evaluation. This alternative formulation is
equivalent to the existing semantics and mainly motivated by the
soundness proof of our type system for bound analysis.  However, the
cost semantics is a natural approach and different enough from its
predecessors~\cite{Spoonhower:2008:SPP:1411204.1411240,DBLP:journals/entcs/Minamide99}
to be of interest in its own right.

\emph{Our second technical contribution} is the type system for
deriving bounds on the heap-space for programs with perfect GC. The
type system is an extension of type-based automatic amortized resource
analysis
(AARA)~\cite{Jost03,Jost10,VasconcelosJFH15,HoffmannAH10,HoffmannW15,NgoDFH16}. AARA
is template-based technique that introduces potential functions to
efficiently automatically reduce bound inference to linear
programming. Existing type systems based on AARA can derive bounds on
the highwater mark of the heap usage for programs with manual
deallocation~\cite{Jost10}, but can only derive a bound on the number
number of total heap allocations for programs with
GC~\cite{HoffmannW15}. This is usually a crass over-approximation of
the actual memory requirement. Our extension is based on the
observation that deallocation of a perfect collector can be modeled
with destructive pattern matching (deallocate the matched cell) if
data structures are used in a linear way. In the type system, we
extend this observation to non-linear programs and use destructive
pattern matching to accurately model deallocation even if data is
shared.

\emph{The third technical contribution} is to prove the soundness of
the extended AARA with respect to the GC-based cost semantics. The
proof is non-trivial and proceeds in two parts: First, we prove the
soundness of the type system with respect to a semantics that copies
datastructures if they are shared. Second, we prove for all programs
that our GC semantics is using less memory than this copying
semantics. While the proofs are relatively standard, many
details---like relating program states of the two semantics in the
simulation proof---are quite involved. \yue{maybe you want to
  elaborate a bit!?}

The analysis and the cost semantics have been implemented as an
extension to Resource Aware ML (RaML)~\cite{HoffmannAH10,HoffmannW15}. RaML is an
implementation of AARA for a subset of OCaml that can derive
multivariate polynomial bounds. However, we restrict the technical
development in this paper to a simple first-order language with
tuples, lists, and trees. The proofs and ideas carry over the more
complex case of RaML.\footnote{An exception are function closures that
  we discuss in the Section~\ref{sect:conclusion}.}
%
An experimental evaluation shows that the system is able to derive
tight symbolic heap-space bounds for common algorithms. Our results
suggest that our new analysis provides asymptotic bound improvements
to several classes of commonly used functions and programming
patterns. We examine the reasons for these improvements and design
decisions throughout the system.



\section{Setting the Stage}
\label{sect:fop}

In the technical part of the paper, we focus our attention to a first-order, 
strictly evaluated functional language. 
You can think this language to be a simple subset of OCaml or SML. 
The only recursive data type in the language is the list type. 
However, our work extend to the expected algebraic data types definable in RaML.
Being first order, our language does not allow arbitrary local functional definitions. Instead,
all functions are defined at the top level and are mutually recursive by default.
The types of these functions form a signature for the program, and the semantics and typing 
judgments will be indexed by this signature.
Thus, the function types of the language can be expressed 
as arrows between zero-order (base)  types. 
%
Types are formally defined in Figure~\ref{fig:exp}. Like in all
grammars, we provide the abstract (left) and concrete (right) syntax
for every type former.\jan{cite pfpl}
A \emph{signature}  $\Sigma : \ms{Var} \to \ms{FTypes}$ is a map from variables to 
first-order types. 
A \emph{program} $P$ is a $\Sigma$ indexed map from $\ms{Var}$ to pairs 
$(y_f,e_f)_{f \in \Sigma}$, where $\Sigma(y_f) = \tau \to \tau'$, 
and $\Sigma;y_f : \tau \vdash e_f : \tau'$ (the type system is discussed in Section~$\ref{sect:typing}$). 
We write $P : \Sigma$ to mean $P$ is a program with signature $\Sigma$. 

\begin{figure}[t!]
\vspace{-2ex}
\begin{minipage}[t]{0.33\linewidth}
	\[
\begin{array}{r l l l l}
\hspace{-1em}\ms{BTypes} & \tau \,\,\,\,\, ::= \\
	& \irl{nat}                	 			& \irl{nat}											\\
	& \unittyabt                	 			& \unittycst								\\
  & \booltyabt                       & \booltycst                \\
  & \prodtyabt{\tau_1}{\tau_2}       & \prodtycst{\tau_1}{\tau_2}\\
  &\listtyabt{\tau}		& L(\tau)				\\						
  \\
\hspace{-1em}\ms{FTypes} & \rho \,\,\,\,\, ::= \\
	&\irl{arr}(\tau_1;\tau_2) 				& \arrtycst{\tau_1}{\tau_2}\\ 	
\\
\ms{Val}
        & v   \,\,\,\,\, ::= \\
 	& \irl{val}(n)                                			& n 											\\	
 	& \irl{val}(\irl{T})                               			& \irl{T} 								 \\ 
 	& \irl{val}(\irl{F})                                			& \irl{F}								 \\ 
 	& \irl{val}(\irl{Null})                                  & \irl{Null} 								 \\ 
 	& \irl{val}(l)                                			& l 								 \\ 
 	& \irl{val}(\pairexabt{v_1}{v_2})                             & \pairexcst{v_1}{v_2} 					
% \ms{Loc} & l   \,\,\,\,\, ::= \\
%  	& \irl{loc}(l)                                		\\	\\
% \ms{Var} & x   \,\,\,\,\, ::= \\
%  	& \irl{var}(x)                                		\\	
\end{array}
\]
\end{minipage}
\hfill
\begin{minipage}[t]{0.59\linewidth}
\[
\begin{array}{r l l l}
\ms{Exp}
        & e   \,\,\,\,\, ::= \\
 	& \irl{var}(x)                                			& x 											\\	
  & \irl{nat}[n]							& \numeral{n}											\\	
  & \irl{unit}							& ()											\\	
  & \irl{T}							& \irl{T}											\\	
  & \irl{F}	   					& \irl{F}											\\	
  & \ifexabt{x}{e_1}{e_2} & \ifexcst{x}{e_1}{e_2} \\ 
  % & \irl{lam}(x:\tau.e) 						&\lambda \; x : \tau. e 	\\	
  & \irl{ap}(f;x) 					& \appcst{f}{x} 									\\	
  & \irl{tpl}(x_1;x_2)     	& \pairexcst{x_1}{x_2}                								\\	
 	& \paircaseabt{p}{x_1}{x_2}{e_1}					& \paircasecst{p}{x_1}{x_2}{e_1}   \\	
 	& \nilexabt					& []   									\\	
 	& \consexabt{x_1}{x_2}					& x_1::x_2   									\\	
 	& \listcaseexabt{l}{e_1}{x}{xs}{e_2}					& \listcaseexcst{l}{e_1}{x}{xs}{e_2}   \\	
  & \irl{let}(e_1; x : \tau.e_2)			& \irl{let}\; x = e_1 \; \irl{in}\; e_2   \\	
  & \shareabt{x}{x_1}{x_2}{e} &\sharecst{x}{x_1}{x_2}{e}\\ 
\end{array}
\]
\end{minipage}

\caption{Simple Types, Values, and Expressions \yue{change abstract syntax of vars; change nats to ints}}
\label{fig:exp}
\end{figure}

To simplify the presentation, the expressions of our language (see Figure~\ref{fig:exp}) are in \emph{let normal form} (also \emph{A normal form}).
% We allow an extended syntax in the implementation. 
The one nonstandard construct is $\sharecst{x}{x_1}{x_2}{e}$, which we will explain in more 
detail in the following sections. We introduce two distinct notions of \emph{linearity}, one on 
the syntactic level, and one on the semantic level. Syntactic linearity is linearity in 
expression variables, while semantic linearity is linearity in locations (defined below).
We say that a semantics is linear if it respects semantic linearity.

In line the previous works on space cost
semantics~\cite{Spoonhower:2008:SPP:1411204.1411240,DBLP:journals/entcs/Minamide99},
we employ a heap, which persistently binds
locations to values (normalized terms).  As usual, we derive the cost
of a program from the number of heap locations number of heap
locations used during execution. Locations is an infinite set of names
for addressing the heap.
%
For the rest of the paper, we use the following:
$\ms{Stack} \triangleq \{ V \mid V : \ms{Var} \to \ms{Val} \}$
and $\ms{Heap} \triangleq \{ H \mid H: \ms{Loc} \to \ms{Val} \}$
for the set of stacks and heaps respectively.  We refer to a tuple
$\mathcal{S} = (V,H) \in \ms{Stack} \times \ms{Heap}$
as a \emph{context}, a tuple
$\mathcal{C} = (V,H,R,F) \in \ms{Stack} \times \ms{Heap} \times
\mathcal{P}(\ms{Loc}) \times \mathcal{P}(\ms{Loc})$ as a
\emph{configuration}, and finally a pair of configuration and
expression $(\mathcal{C}, e)$
a \emph{computation}.  \yue{do we really need to introduce all these terms?}

\textbf{Reachability}
\label{sect:reachability}
Before we define the rules for the cost semantics, we relate the heap locations to 
expressions and value with the 3-place reachability relation $reach(H,v,L)$ on $\ms{Heap} \times \ms{Val} \times \wp(\ms{Loc})$, where $\wp$ is the powermultiset. 
This is read as ``under heap $H$, the value $v$ reaches the multiset 
of locations $L$''. Write $L = reach_H(v)$ to indicate this is a functional relation 
justified by the (valid) mode $(+,+,-)$.
%
\begin{mathpar}
\inferrule{
	A = reach_H(v_1)\\
	B = reach_H(v_2)
}{
	A \uplus B = reach_H(\pairexcst{v_1}{v_2}) 
} 

\inferrule{
	A = reach_H(H(l))\\
}{
	\{l\} \uplus A = reach_H(l)
} 

\inferrule{
	v \in \mathbb{N} \cup \{\irl{T},\irl{F},\irl{Null}\}
}{
	\emptyset = reach_H(v)
} 
\end{mathpar}
%
I the rules, $\uplus$ is multiset union. For the rest of the paper, we will sometimes mix 
multiset and set operations as the situation calls for. For example, we will write 
$l \in S$ for a multiset $S$ if $S(l) \ge 1$. Complete definitions and notations can
be found in the appendix.
Notice that primitives and types with statically-known sizes are stack-allocated 
($\booltycst, \irl{nat}, \prodtycst{\tau_1}{\tau_2}$) and use no heap cells. \yue{$<$- a bit out of place?}
The notion of reachability naturally lifts to expressions:
\begin{align*}
  &locs_{V,H}(e) = \biguplus\limits_{x \in FV(e)} reach_H(V(x))
\end{align*}
Where $FV : \ms{Exp} \to \mathcal{P}(\ms{Var})$ denotes the set of free-variables of expressions as usual.\\

\textbf{Towards the Garbage Collection Cost Semantics}
Now we are ready to give a first attempt to modeling the cost semantics for a
tracing garbage collector. Before we present our new semantics, we explain an
existing cost semantics we experimented with~\cite{DBLP:journals/entcs/Minamide99}. Judgements have the form
%
$V,H,R \vdash e \Downarrow^s v,H$,
%
which can be read as follows. Under stack $V \in \ms{Stack}$, heap $H \in \ms{Heap}$, 
and continuation set $R \subseteq \ms{Loc}$, $e$ evaluates to $v$ 
and $H'$ using $s$ heap locations. The idea is that $R$ keeps track of the set of locations 
necessary to complete the evaluation \emph{after} $e$ is evaluated (hence the name continuation).
For example, we have the let rule: 
%
\[
	\inferrule{
		V,H,R \cup locs_{V,H}(x.e_2) \vdash e_1 \Downarrow^{s_1} v_1,H_1\\
		V[x \mapsto v_1],H,R \vdash e_2 \Downarrow^{s_2} v_2,H_2\\
	}{
		V,H,R \vdash \irl{let}(e_1; x : \tau.e_2) \Downarrow^{\max{s_1,s_2}} v_2,H_2
	}
\]

Notice that to evaluate $e_1$, we have to extend the continuation $R$ with locations in $e_2$, which
will be used \emph{after} $e_1$ is evaluated. The total space used is the max of the 
component, indicating that locations used for $e_1$ can be reused for $e_2$. 
This is clear when we look at the variable rule. \yue{add dom to multiset size}
%
\[
	\inferrule{
		V(x) = v
		}{
			V,H,R \vdash x \Downarrow^{|R \cup reach_H(v)|} v,H
			}
\]
%
It states that evaluating a variable $x$ requires the locations reachable from $x$ as well as 
the continuation set $R$. While this way of counting heap locations does model a tracing garbage 
collector, it is not compatible with the existing type systems for amortized analysis. In these
systems, the type rules count the heap locations as data is created, i.e.\ at each data constructor.
Thus looking up a variable incurs no cost, since it was accounted for during creation. This mismatch
between the dynamics and statics of language prevent us from proving the soundness of the analysis. 

%------------------------------------------------------------------------------

\section{Garbage Collection Cost Semantics}
\label{sect:semantics}

In this section, we present our novel cost semantics by combining
\emph{freelist semantics} from~\cite{Hofmann:2003:SPH:604131.604148}
with the cost semantics for modeling perfect
GC~\cite{DBLP:journals/entcs/Minamide99} the we discussed in the
previous section. The resulting semantics, called \gcSem, is well suited for
proving the soundness of the novel type-based bound analysis.

The garbage collection cost semantics \gcSem{} is defined by a collection of judgement of the form
\[
\mathcal{C} \; \vdash_{P : \Sigma} e \Downarrow v, H', F'
\]
where $\mathcal{C}$ is a configuration usually written as $V,H,R,F$. \yue{define configurations here!}
Because the signature $\Sigma$ for the mapping of function names to first-order functions 
does not change during evaluation, we drop the subscript $P:\Sigma$ from $\vdash_{P:\Sigma}$ 
when the context of evaluation is clear.
The evaluation judgment states that under stack $V$, heap $H$, continuation set $R$,
freelist $F$, and program $P$ with signature $\Sigma$, the expression $e$ evaluates to value $v$, 
and engenders a new heap $H'$ and freelist $F'$. Compared to the previous section, the key
ingredient we added is the freelist, which will serve as the set of available 
locations.

The semantics \gcSem{} is to designed to model the heap usage of a program running with a 
tracing counting garbage collector: whenever a heap cell becomes unreachable from the 
root set, it becomes collected and added to the freelist as available for reallocation.
As before, the continuation set $R$ represents the set of locations 
required to compute the continuation \emph{excluding} the current expression.
We define the  \emph{root set} as the union of the locations in the continuation set $R$ 
and the locations in the current expression $e$. 

The inference rules for the semantics are given in Figure~\ref{fig:costsem}.
For example, the rule F:Let for let expressions
states that, to evaluate the expressions $\irl{let}(e_1; x {:} \tau.e_2)$, we evaluate the first 
expression with the corresponding restricted stack $V_1$ and a expanded continuation set $R'$. 
The extra locations come from the free variables of $e_2$ (not including the bound variable $x$),
which we cannot collect during the evaluation of $e_1$. Next, we extend the restricted stack 
$V_2$ with the result $v_1$, and evaluate $e_2$ with this stack and the original continuation 
set $R$. The other rules are similar. \yue{explain one more rule if we have space}

\begin{figure}[t!]
  \centering
\small
\begin{mathpar}
\infern{
	V_1 = V\restriction_{FV(e_1)}\\
  R' = R \cup locs_{V_2,H}(\irl{lam}(x : \tau.e_2))\\
  V_1,H,R',F \vdash e_1 \Downarrow v_1,H_1,F_1\\
	V_2' = (V[x \mapsto v_1])\restriction_{FV(e_2)}\\
  g = \{ l \in H_1 \mid l \notin F_1 \cup R \cup locs_{V_2',H_1}(e_2) \}\\
  V_2',H_1,R, F_1 \cup g \vdash e_2 \Downarrow v_2,H_2,F_2 \\
}{
  V,H,R,F \; \vdash \irl{let}(e_1; x : \tau.e_2) \Downarrow v_2,H_2,F_2
}

\infern{
  V(x) = \irl{T}\\
  g = \{l \in H \mid l \notin F \cup R \cup locs_{V,H}(e_1)\}\\
	V' = V\restriction_{FV(e_1)}\\
  V',H,R,F \cup g\; \vdash e_1 \Downarrow v, H',F'
}{
  V,H,R,F \; \vdash \ifexabt{x}{e_1}{e_2} \Downarrow v, H',F'
}

\infern{
	V(x) = \irl{F}\\
  g = \{l \in H \mid l \notin F \cup R \cup locs_{V,H}(e_2)\}\\
	V' = V\restriction_{FV(e_2)}\\
  V',H,R,F \cup g \; \vdash e_2 \Downarrow v, H',F'
}{
  V,H,R,F \; \vdash \ifexabt{x}{e_1}{e_2} \Downarrow v, H' ,F'
}

% function

\infern{
  V(x) = v'\\
  P(f) = (y_f,e_f)\\
  g = \{l \in H \mid l \notin F \cup R \cup locs_{V,H}(e_f)\}\\
  [y_f \mapsto v'],H,R,F \cup g \; \vdash e_f \Downarrow v,H',F'\\
}{
  V,H,R,F \; \vdash \appcst{f}{x} \Downarrow v,H',F'
}

% lists

\infern{
}{
  V,H,R,F \; \vdash \nilexabt \Downarrow \irl{val(Null)},H,F
} 

\infern{
  v = \pairexcst{V(x_1)}{V(x_2)}\\
	l \in F\\
  H' = H\{l \mapsto v\}
}{
	V,H,R,F \; \vdash \consexcst{x_1}{x_2} \Downarrow l,H' ,F \setminus \{l\}
}



\infern{
  V(x) = \irl{Null}\\
	V' = V\restriction_{FV(e_1)}\\
  g = \{l \in H \mid l \notin F \cup R \cup locs_{V,H}(e_1)\}\\
  V',H,R,F \cup g \; \vdash e_1 \Downarrow v, H',F' \\
}{
  V,H,R,F \; \vdash \listcaseexcst{x}{e_1}{x_h}{x_t}{e_2} \Downarrow v,H',F'
}

\infern
{ V(x) = v\\
}
{V,H,R,F \; \vdash x \Downarrow v,H,F}

\infern{
  V(x) =  l\\
  H(l) = \pairexcst{v_h}{v_t} \\
	V'' = (V[x_h \mapsto v_h, x_t \mapsto v_t])\restriction_{FV(e_2)}\\
  g = \{l \in H \mid l \notin F \cup R \cup locs_{V'',H}(e_2)\}\\
  V'',H,R,F \cup g \; \vdash e_2 \Downarrow v, H',F' \\
}{
  V,H,R,F \; \vdash \listcaseexcst{x}{e_1}{x_h}{x_t}{e_2} \Downarrow v,H',F'
}


\inferr{
  V,H,R,F \; \vdash \sharecst{x}{x_1}{x_2}{e} \Downarrow v,H'',F'
}{
  V = V'[x \mapsto v']\\
  V'[x_1 \mapsto v',x_2 \mapsto v'],H',R,F \; \vdash e \Downarrow v,H'',F'
}(\text{F:Share})
\end{mathpar}
  \caption{Cost Semantics for Perfect Garbage Collection}
  \label{fig:costsem}
\end{figure}
Note that in contrast to the semantics in the previous section, evaluating a variable does not incur
cost. This ensures that we will be able prove the soundness of the type system. 
Also, since we don't allow local function definitions, we do not create closures
during evaluation. % However, our implementation uses closures to implement the global block of 
% function definitions.
\yue{the following doesn't seem to belong here. Make the forward
  reverence more abstract if you really want it.} Also note that we restrict the domain of
the stack to the appropriate variables during evaluation. This is only
to facilitate the proof of the linearity of \copySem, and not
necessary for the implementation. These issues are discussed in
\ref{sect:implementation}.

\begin{wrapfigure}{r}{0.5\textwidth}
	\vspace{-20pt}
		\begin{center}
\begin{verbatim}
type btree = Leaf | Node of int*btree*btree

let dfs t x =

  let rec dfs_aux queue =
    match queue with
      | [] -> None
      | t::ts -> 
	match t with
          | Leaf -> dfs_aux ts
          | Node(a,t1,t2) -> 
	    if a = x then 
	      Some t 
	    else 
	      dfs_aux (t1::t2::ts)
  in

  dfs_aux [t]
\end{verbatim}
			\end{center}
				\vspace{-20pt}
			\caption{dfs algorithm}
		\vspace{-10pt}
\label{fig:dfs}
\end{wrapfigure}


For example, we can implement and analyze the depth-first search (dfs) on trees 
in Figure~\ref{fig:dfs}.
The search starts at the root, and checks if the node is the target. If not, 
the left and right subtrees are queued in that order, and recursively searched.
%
To analyze the heap usage under \gcSem{}, assume that a tree \texttt{t} is given 
as input. To start off the tail-recursive helper, we need to allocate 2 heap locations,
1 for the cons cell with \texttt{t} and 1 for nil. That is the entire memory overhead: 
We can show the helper \texttt{dfs\_aux} does not add additional cost. Since the whole program is 
linear (no variable sharing), constructors can be deallocated in pattern matches.
If \texttt{queue} is nil, then its location is collected and allocated to \texttt{None}.
If \texttt{queue} is \texttt{t::ts}, then we have 2 cases. In case \texttt{t} is a leaf, 
the search continues, with no space used. If \texttt{t} is a node, then the location for the node
is collected and either used to for \texttt{Some t} or used together with the location for 
the cons in \texttt{t::ts} to allocate \texttt{t1::t2::ts}, and the search continues without 
overhead. Since runs through \texttt{dfs\_aux} do not require additional heap locations, 
we have zero overhead. Thus, the function dfs has a constant space cost of 2.

% Now, we can run dfs on an example tree 
% \texttt{t = Node(1,Node(2,Node(4,Leaf,Leaf),Leaf),Node(3,Leaf,Leaf))}:
% \[
% \emptyset,\emptyset,\emptyset,\{l_1,...,l_{11}\} 
% 	\vdash \texttt{dfs t 3}, l_1, H', 
% 	\{l_2, l_4, l_6, l_7, l_9, l_{10}, l_{11}\}
% \] for some heap $H'$.

% \begin{wrapfigure}{l}{0.5\textwidth}
% 	\vspace{-20pt}
% 		\begin{center}
% \begin{verbatim}
% 	l1 |--> Node@[l8] 
% 	l2 |--> <freed>
% 	l3 |--> Null 
% 	l4 |--> <freed>
% 	l5 |--> Null
% 	l6 |--> <freed>
% 	l7 |--> <freed>
% 	l8 |--> <(Cint 3), Leaf@[l3], Leaf@[l5]>, 
% 	l9 |--> <freed>
% 	l10 |--> <freed>
% 	l11 |--> <freed>
% \end{verbatim}
% 		\end{center}
% 				\vspace{-20pt}
% 			\caption{$H'$}
% 		\vspace{-10pt}
% \label{fig:heap}
% \end{wrapfigure}

% From this run, we see that the space overhead of dfs is 2 heap locations, which agrees with 
% our manual derivation. In the next section, we see that the type system will also be 
% able to derive this optimal bound. 


\yue{either replace example or add trees.}

\yue{explain where allocation happens in the semantics. cost metric: 1 cell per constructor; rest on stack }

\yue{explain how this is a cost semantics; what's the relation to blelloch's semantic? size of the minimal initial freelist is blelloch's cost annotation!}

\yue{dfs example: replace this with append and appendTwice; in appendTwice, use explicit sharing}

\section{Automatic Amortized Heap-Space Analysis with GC}
\label{sect:aara}

{\bf Automatic Amortized Resource Analysis (AARA)}
%
The idea of AARA~\cite{Jost03,Jost10,HoffmannAH10,HoffmannW15} is to automate the potential method of amortized
analysis using a type system.  Types introduce potential function that
map data structures of the given type to non-negative numbers. The
type rules ensure that there is always sufficient potential to cover
the evaluation cost of the next step and the potential of the
next program state.

To illustrate the idea, we informally explain the linear potential method for the dfs algorithm in Figure~\ref{fig:dfs}
We will use the allocation/heap metric which simply counts the number of cons constructor calls during the evaluation.%
\footnote{This is in contrast to the highwater mark for the GC semantics \gcSem{} that is targeted by our new analysis.}
With this metric, the cost of evaluating $\text{dfs}(t,n)$ is $2m+3$, where $m$ is the number 
of \texttt{Node} constructors in the input.
%

\yue{1) what's the cost of append and appendTwice with the metric ?}

\yue{2) what are the types of the functions in aara? what do they intuitively mean?}

\yue{3} how does sharing work in appendTwice? What are the types of the variables in the code? (need to add potential)

\yue{4) how do we derive the types automatically? (I can write that later)}

\jan{Better intro for AARA, polynomial potential somewhere}

\textbf{Linear Potential Functions}
Before giving the type rules, we need to formalize linear potential as explained above.
Since potential is associated with the \emph{structure} of a value and not the particular heap 
locations, we need a mapping from
heap values to semantic values (or structures) of a type. 
First give a denotational semantics for (define the structures of) the first-order types: 

\begin{align*}
	\denote{\unittyabt} &= \{\val{\irl{Null}}\}\\
	\denote{\booltyabt} &= \{\val{\irl{T}}, \val{\irl{F}}\}\\
	\denote{\irl{nat}} &= \mathbb{N}\\
\pairexcst{a_1}{a_2} &\in \denote{\prodtycst{A_1}{A_2}} 
	\text{ if } a_1 \in \denote{A_1} \text{ and } a_2 \in \denote{A_2}\\
\nilexcst &\in \denote{L(A)}\\
\consexcst{a}{l} &\in \denote{L(A)} \text{ if } a \in \denote{A} \text{ and } l \in \denote{L(A)}\\
\end{align*}

Where semantic set for each type is the least set such that the above holds. Write $[a_1,...,a_n]$ for $\consexcst(a_1,...,\consexcst(a_n,\nilexcst))$.
We also refer to the elements of a semantic set as structures. \\

Now we give the judgements relating heap values to semantic values, in the form \fbox{$H \vDash v \mapsto a : A$}, which can be read as: under heap $H$, heap value $v$ defines the semantic value $a \in \denote{A}$.  

\begin{mathpar}
\inferr{
  H \vDash \val{n} \mapsto n : \irl{nat}
}{
  n \in \mathbb{Z}
}(\text{V:ConstI})

\inferr{
	H \vDash \val{\irl{Null}} \mapsto \val{\irl{Null}} : \unittyabt
}{
}(\text{V:ConstI})

\inferr{
  H \vDash \val{\irl{Null}} \mapsto \val{\irl{Null}} : L(A)
}{
  A \in \ms{BType}
}(\text{V:Nil})

\inferr{
  H \vDash \val{\irl{T}} \mapsto  \val{\irl{T}} : \booltyabt
}{
}(\text{V:True})

\inferr{
  H \vDash \val{\irl{F}} \mapsto \val{\irl{F}}  : \booltyabt
}{
}(\text{V:False})

	\inferr{
		H \vDash \pairexcst{v_1}{v_2} \mapsto \pairexcst{a_1}{a_2} : \prodtycst{A_1}{A_2}
	}{
		H \vDash v_1 \mapsto a_1 : A_1 \\
		H \vDash v_2 \mapsto a_2 : A_2
	}(\text{V:Pair})
	
\inferr{
  H \vDash l \mapsto [a_1,\ldots,a_n] : L(A)
}{
  l \in \ms{Loc}\\
  H(l) = \pairexcst{v_h}{v_t}\\
  H \vDash v_h \mapsto a_1 : A\\
  H \vDash v_t \mapsto [a_2,\ldots,a_n] : L(A)
}(\text{V:Cons})
\end{mathpar}

Given a stack $V$, we write $H \vDash V : \Gamma$ if $dom(V) = dom(\Gamma)$ and
for every $x : A \in \Gamma$, $H \vDash V(x) \mapsto a : A$ for some $a \in \llbracket A \rrbracket$.

We introduce linear potential for structures corresponding to the base types. The definition of
linear potential is standard material, and can be found in \cite{Hoffmann11}, which is also
a good source for an introduction to AARA. Below is the grammar for resource-annotated types:

\[
\begin{array}{r l l l}
\ms{BTypes} & \tau \,\,\,\,\, ::= \\
	&...\\
	&\irl{list}^p(\tau)		& L^p(\tau)				\\						
  \\
\ms{FTypes} & \rho \,\,\,\,\, ::= \\
	&\irl{arr}(\tau_1;\tau_2;p;q) 				& \tau_1 \xrightarrow{p/q} \tau_2\\ 	
\end{array}
\]

The intended meaning is that a list of $L^p(\tau)$ has $p$ units of potential per 
cons cell, and a functions of type $\tau_1 \xrightarrow{p/q} \tau_2$ takes constant potential 
$p$ to run and $q$ is the constant potential left afterwards.

With linear potential, each component of a structure is associated with a constant amount of 
potential.  Given a structure $a$ in a heap $H$, where  $H \vDash v \mapsto a : A$, we define 
its potential $\Phi_H(a : A)$ by recursion on $A$: 

\begin{align*}
&\Phi_H(a : A) = 0 &A \in \{\unittycst, \booltyabt, \irl{nat}\}\\
&\Phi_H(\pairexcst{a_1}{a_2} : \prodtycst{A_1}{A_2}) = \Phi_H(a_1 : A_1) + \Phi_H(a_2 : A_2)\\
&\Phi_H([a_1,...a_n] : L^p(A)) = p\cdot n + \sum_{1 \le i \le n} \Phi_H(a_i : A)  
\end{align*}

Now define $A \curlyvee A_1,A_2,n$ as the sharing relation for resource-annotated types:
\begin{align*}
	&L^p(A) \curlyvee^n L^q(A_1),L^r(A_2) & \text{if } p = q + r + n \;\text{and}\; 
			A \curlyvee^n A_1,A_2\\
	&\prodtycst{A}{B} \curlyvee^n \prodtycst{A_1}{B_1}, \prodtycst{A_2}{B_2}
		&\text{ if } A \curlyvee^n A_1,A_2 \text{ and } B \curlyvee^n B_1,B_2\\
	&A \curlyvee^n  A,A& \text{ if } A \in \{\unittycst, \booltycst, \irl{nat}\}\\
\end{align*}
The sharing relation captures the amount of potential needed to copy a type $A$ where each 
cons node in any structure in $\llbracket A \rrbracket$ has a copying overhead $n$.

\textbf{Type Rules}
\label{sect:typing}
The type system $\fogc$ consists of rules of the form \fbox{$\Sigma;\Gamma \sststile{q'}{q} e : A$}, 
read as under signature $\Sigma : \ms{Var} \to \ms{FTypes}$, 
context $\Gamma : \ms{Var} \to \ms{BTypes}$, $e$ has type $A$ starting with $q$ units of 
constant potential and ending with $q'$ units.

The type system is based on the affine type system in \cite{HoffmannW15}. 
We give a review of the rules below.
Since we are interested in the number of heap locations, 
there is an implicit side condition in all rules
which ensures all constants are assumed to be nonnegative.

\begin{mathpar}
\inferr{
  \Sigma; x : B \sststile{q}{q} x : B
}{
}(\text{L:Var})

\inferr{
  \Sigma; x : A \sststile{q'}{q} f(x) : B
}
{
  \Sigma(f) = A \xmapsto{q/q'} B
}

\inferr{
  \Sigma; \Gamma, x : \irl{bool} \sststile{q'}{q} \ifexcst{x}{e_t}{e_f} : B
}{
  \Sigma; \Gamma \sststile{q'}{q} e_t : B \\
  \Sigma; \Gamma \sststile{q'}{q} e_f : B
}(\text{L:Cond})

\inferr{
  \Sigma; x_1 : A_1, x_2 : A_2 \sststile{q}{q} \pairexcst{x_1}{x_2} : \prodtycst{A_1}{A_2}
}{
}(\text{L:Pair})

\inferr{
  \Sigma; \Gamma, x : (A_1,A_2) \sststile{q'}{q} \paircasecst{x}{x_1}{x_2}{e} : B
}{
  \Sigma; \Gamma, x_1 : A_1, x_2 : A_2 \sststile{q'}{q} e : B
}(\text{L:MatP})

\inferr{
  \Sigma; \emptyset \sststile{q}{q} \irl{nil} : L^p(A)
}{
}(\text{L:Nil})

\inferr{
  \Sigma; x_h : A, x_t : L^p(A) \sststile{q}{q+p+1} \consexcst{x_h}{x_t} : L^p(A)
}{
}(\text{L:Cons})

\inferr{
  \Sigma; \Gamma, x : L^p(A) \sststile{q'}{q} \listcaseexcst{x}{e_1}{x_h}{x_t}{e_2} : B
}{
  \Sigma; \Gamma \sststile{q'}{q} e_1 : B \\
  \Sigma; \Gamma, x_h : A, x_t : L^p(A) \sststile{q'}{q + p + 1} e_2 : B
}(\text{L:MatL})

\inferr{
  \Sigma; \Gamma, x : A \sststile{q'}{q} \sharecpcst{x}{x_1}{x_2}{e} : B
}{
  A \;\curlyvee \;A_1, A_2\\
  \Sigma; \Gamma, x_1 : A_1, x_2 : A_2 \sststile{q'}{q} e : B
}(\text{L:ShareCopy})

\inferr{
  \Sigma; \Gamma_1, \Gamma_2 \sststile{q'}{q} \irl{let}(e_1; x : \tau.e_2) : B
}{
  \Sigma; \Gamma_1 \sststile{p}{q} e_1 : A \\
  \Sigma; \Gamma_2, x : A \sststile{q'}{p} e_2 : B
}(\text{L:Let})

\end{mathpar}
Recall that we gave the bound $2m+3$ to dfs in the introduction.
Formally, this means we can give the following type derivation to dfs:
\[
	\Sigma; \texttt{t} : \texttt{btree}^2(\irl{nat}), \texttt{x} : \irl{nat} 
		\sststile{0}{3} \texttt{dfs t x} : \irl{nat\_ option}
\]

Where $\Sigma = [\texttt{dfs} : 
	\prodtycst{\texttt{btree}^2(\irl{nat})}{\irl{nat}} \xrightarrow{3/0} \irl{nat\_ option}]$.\\

The new type system replaces the rules L:MatL and L:Share. The observation is that if we ensure 
that locations are used linearly, we can use destructive pattern matching to model 
local garbage collection by returning the potential associated with the constructor location
(notice the extra $+1$ in the second premise):

\[
\inferr{
  \Sigma; \Gamma, x : L^p(A) \sststile{q'}{q} \listcaseexcst{x}{e_1}{x_h}{x_t}{e_2} : B
}{
  \Sigma; \Gamma \sststile{q'}{q} e_1 : B \\
  \Sigma; \Gamma, x_h : A, x_t : L^p(A) \sststile{q'}{q + p + 1} e_2 : B
}(\text{L:MatL})
\]

This is validated by the fact (Lemma \ref{itm:na}) that in the auxiliary linear cost semantics 
\copySem once a cons-cell is matched on, 
there can be no live references from the root set to it, and thus 
we are justified in restituting the potential to type the subexpression $e_2$. The next 
interesting rule is L:Share:

\[
\inferr{
  \Sigma; \Gamma, x : A \sststile{q'}{q} \sharecpcst{x}{x_1}{x_2}{e} : B
}{
  A \;\curlyvee^1 \;A_1, A_2\\
  \Sigma; \Gamma, x_1 : A_1, x_2 : A_2 \sststile{q'}{q} e : B
}(\text{L:Share})
\]

To share a variabe of type $A$, we need to split the potential between two new annotated types 
$A_1$ and $A_2$ as usual. In addition, we have to pay an ``overhead'' of 1 for every cons node 
in any structure in $\llbracket A \rrbracket$. This is used to model the copying overhead 
in the sharing rule in \copySem.

Now, we can give the now \emph{constant} space overhead bound to dfs:
\[
	\Sigma; \texttt{t} : \texttt{btree}^0(\irl{nat}), \texttt{x} : \irl{nat} 
		\sststile{0}{2} \texttt{dfs t x} : \irl{nat\_ option}
\]

Where $\Sigma = [\texttt{dfs} : 
	\prodtycst{\texttt{btree}^0(\irl{nat})}{\irl{nat}} \xrightarrow{2/0} \irl{nat\_ option}]$.\\

In previous versions of RAML, the typing judgment is parametrized by a \emph{cost metric} 
$m : \ms{res\_const \to \mathbb{Q}}$, which assigns a rational constant to 
the set of control-flow points (\ms{res\_const}). 
Since the cost for all program construct is zero save for the cons
data constructor, we elide the cost metric altogether. Although we defined the constructor to cost
1 heap location (as shown in L:Cons and L:MatL), it can be any constant as long as the introduction
and elimination rules agree on that constant. Thus we can extend the type system to accurately track
closure sizes and constructor which vary in size depending on the argument (more in 
\ref{sect:future-work}).

Futhermore, note that given a judgment $\Sigma;\Gamma \sststile{q'}{q} e : A$, there are 
infinitely many admissible judgments $\Sigma;\Gamma \sststile{q' + k}{q + k} e : A$ 
for all $k \in \mathbb{N}$. The analysis module will export the constraints generated 
by the type system into an LP-solver which minimizes all coefficients, so that the 
smallest admissible $q,q'$ will be used in the resulting symbolic bound.
%------------------------------------------------------------------------------

\section{Soundness of $\fogc$}

We seek to prove the following theorem: 

\begin{theorem}[Soundness]
\label{itm:soundness} let $H \vDash V : \Gamma$, $\Sigma; \Gamma \sststile{q'}{q} e : B$,
$V,H \; \vdash e \Downarrow v, H'$, and $H' \vDash v \mapsto a : A$.
Then $\forall C \in \mathbb{Q}^{+}$ and $\forall F,R \subseteq \ms{Loc}$,
if $|F| \ge \Phi_{V,H}(\Gamma) + q + C$,
then there exists a value $w$, and a freelist $F'$ s.t.
\begin{enumerate}
	\item $V,H,R,F \vdash^{\gcSem} e \Downarrow w, Y', F'$
	\item $\veq{H'}{Y'}{v}{w}$
\end{enumerate}
\end{theorem}

Where $V,H \; \vdash e \Downarrow v, H'$ is a judgment from the operational semantics
derived from \gcSem and $\veq{H'}{Y'}{v}{w}$ is value equivalence. The theorem states that,
given a terminating expression,
and given a freelist that is sufficiently large (as predicated by the type derivation), 
a run with \gcSem will normalize to an equivalent value.

To facilitate the proof, we define an intermediate semantics \copySem 
which is semantically linear. The plan has two stages: show \copySem over 
approximates \gcSem, meaning that any computation that succeeds with \gcSem will succeed with 
an equally-sized or smaller freelist with \gcSem. Then we 
show $\fogc$ is sound w.r.t. \copySem, and thus by the previous step sound w.r.t \gcSem.

\textbf{Linear Garbage Collection Cost Semantics}
\label{sect:copy}
In order to establish the soundness of the our intended semantics \gcSem, we need an 
intermediary semantics which is \emph{semantically linear}: \copySem.  
As mentioned in \ref{sect:fop}, this means that locations are linear, i.e. no location can be 
used twice in a program. Thus, variable sharing is achieved via \emph{copying}: 
the shared value is created by allocating a fresh set of locations from the freelist and copying the 
locations of the original value one by one. This is also sometimes referred to as deep copying.
Let $copy(H,L,v,H',v')$ be a 5-place relation on 
$\ms{Heap} \times \mathcal{P}(\ms{Loc}) \times \ms{Val} \times \ms{Heap} \times \ms{Val}$. 
Similar to reachability, we write this as 
$H',v = copy(H,L,v)$ to signify the intended mode for this predicate: $(+,+,+,-,-)$.
\begin{mathpar}
	\inferr{
		H,v = copy(H,L,v)	
	}{
		v \in \{n,\irl{T},\irl{F},\irl{Null}\}
	}

	\inferr{
		H'\{l' \mapsto v\},l' = copy(H,L,l) 
	}{
		l' \in L\\
		H',v = copy(H,L \setminus \{l'\},H(l)) 
	}

\inferr{
	H_2,\pairexcst{v_1'}{v_2'} = copy(H,L,\pairexcst{v_1}{v_2})
}{
	L_1 \sqcup L_2 \subseteq L\\
	|L_1| = |dom(reach_H(v_1)|\\
	|L_2| = |dom(reach_H(v_2)|\\
	H_1,v_1' = copy(H,L_1,v_1)\\
	H_2,v_2' = copy(H_1,L_2,v_2)\\
}
\end{mathpar}

Primitives require no cells to copy; a location value is copied recursively; 
a pair of values is copied sequentially, and the total number of cells required 
is the size of the reachable set of the value.  
Now, consider \gcSem with the share rule F:Share replaced with the following: 

\[
\inferrule{
	V(x) = v\\
  L \subseteq F\\
  |L| = |dom(reach_H(v'))|\\
  H',v'' = copy(H,L,v')\\
	V_2 = (V[x_1 \mapsto v',x_2 \mapsto v'']) \restriction_{FV(e)}\\
	F' =	F \setminus L\\
	g = \{l \in H \mid l \notin F' \cup R \cup locs_{V_2,H}(e)\}\\
 	V_2,H',R,F' \sqcup g \; \vdash e \Downarrow v,H'',F'
}{
  V,H,R,F \; \vdash \sharecpcst{x}{x_1}{x_2}{e} \Downarrow v,H'',F'
}(\text{E:Share})
\]

To share a variable, we first copy the shared value; the number of cells required is equal to the
size of the reachable set from the value. This copying sharing semantics is what justifies the 
analysis to use restitute the potential when matching on a cons node, 
since even if the node was shared, we had to pay for the cost by copying the node when sharing the 
original value. Next, we restrict the stack to the appropriate variables. 
Lastly, any locations not reachable from the current subexpression $e$ is collected. This is 
for the case when a variable is shared but not used later.  

Intuitively, we expect that any terminating compuation
with \copySem has a corresponding run with \gcSem that can be instantiated with 
an equally-sized or smaller freelist. Although this seems quite straightforward to prove, a complete
characterization of the relationship of between the space allocations of two runs with each 
semantics is necessary. To motivate this, consider the following proof attempt: 

\begin{attempt}
	Let $\mathcal{C_2} = (V,H,R,F)$ be a configuration and $(\mathcal{C_2}, e)$ 
	be a linear computation. Given that 
	$\mathcal{C}_2 \vdash^{\mathsf{copy}} e \Downarrow v,H',F'$, and $H' \vDash v \mapsto a : A$, 
	for all configurations $\mathcal{C}_1 = (W,Y,R,M)$ such that $W,Y \sim V,H$ and $|M| = |F|$,
there is exists a triple
$(w,Y',M') \in \ms{Val} \times \ms{Heap} \times \ms{Loc}$ s.t.
	\begin{enumerate}
			\item $\mathcal{C}_1 \vdash^{\mathsf{free}} e \Downarrow w,Y',M'$
			\item $\veq{H'}{Y'}{v}{w}$
			\item $|M'| \ge |F'|$
	\end{enumerate}
\end{attempt}

We proceed with induction on the derivation of the judgment in \copySem. 
Almost every case goes through, save for E:Let. 
First, we get $W_1,Y \sim V_1,H$ and We have the following from induction on the first premise:

\begin{enumerate}
	\item $W_1,Y,R',M \vdash^{\mathsf{free}} e \Downarrow w_1,Y_1,M_1$
	\item $\veq{H_1}{Y_1}{v_1}{w_1}$
	\item $|M_1| \ge |F_1|$
\end{enumerate}

To instantiate the induction hypothesis on the second premise, we need to show that, among 
other things, $|M_1 \cup j| \ge |F_1 \cup g|$, where $j$ is the set of collected locations in 
the \gcSem judgment. We cannot show this precisely because $g$ might contain more cells 
then $j$ due to the linearity of \copySem, thus preventing a piecewise comparison. 
But of course $|j|$ is always less than $|g|$, since \gcSem doesn't copy to share 
values! This shows that there is a mismatch between the induction hypothesis and the relationship
between the sizes of the respective freelists and the garbage sets. We present the following 
criteria which characterizes the required equivalence between two configuration,
called \emph{copy extension}.

\begin{definition}
A configuration $\mathcal{C}_2 = (V_2,H_2,R_2,F_2)$ is a \emph{copy extension} of another configuration
$\mathcal{C}_1 = (V_1,H_1,R_1,F_1)$ iff
\begin{enumerate}
\item $V_1,H_1 \sim V_2,H_2$
\item There is a proper partition $\gamma : dom(H_1) \setminus F_1 \to \mathcal{P}(dom(H_2) \setminus F_2)$ 
such that for all $l \in dom(\gamma)$, $|\gamma(l)| = reach_{H_1}(V_1)(l) + R_1(l)$
\item for all $l \in dom(\gamma)$, $x \in dom(V_1)$, valid sequence of directions $P$ w.r.t $V_1(x)$,
	$|reach_{H_2}(V_2(x;P)) \cap \gamma(l)| = reach_{H_1}(V_1(x;P))(l)$.
\item $R_1 \subseteq dom(H_1) \setminus F_1$ and 
	for all $l \in R_1$, $|\gamma(l) \cap R_2| = R_1(l)$
\item $|F_1| = |F_2| + |\oh{\gamma}|$, where 
	$\oh{\gamma} = \bigcup_{P \in ec(\gamma)} P \setminus (rep(P))$
\end{enumerate}
Write this as $\mathcal{C}_1 \preceq \mathcal{C}_2$.
\end{definition} 
The intention is that $\mathcal{C}_2$ is a configuration for initiating an evaluation using \copySem
, and $\mathcal{C}_1$ a configuration for \gcSem. 
The first condition is the straightforward context equivalence.
The second condition requires the existence of 
a mapping $\gamma$ that tells us given a location in $H_1$, which locations in $H_2$ 
are shared instances. For example, consider the expression: 

\begin{verbatim}
share x as x1, x2 in e
\end{verbatim}

Where the stack is $[\texttt{x} \mapsto 1]$, and the heap equals 
$[1 \mapsto \pairexcst{0}{\irl{Null}}]$, i.e. \texttt{x} is the list \texttt{[0]}.
Running with \gcSem, the stack becomes 
$[\texttt{x1} \mapsto 1,\texttt{x2} \mapsto 1]$, and the heap does not change. With 
\copySem, we allocate a new location in the heap:
$[1 \mapsto \pairexcst{0}{\irl{Null}},2 \mapsto \pairexcst{0}{\irl{Null}}]$, and the 
stack changes accordingly: $[\texttt{x1} \mapsto 1,\texttt{x2} \mapsto 2]$.
Now $\gamma$ would map 1 to $\{1,2\}$, since both are shared instances of the former.

Thus, each $\gamma(l)$ is mapped to a disjoint subset in $H_2$, and each location in $H_2$ 
would have a representative in $H_1$. Furthermore, we noticed it is crucial to include the 
fact that the size of $\gamma(l)$ must be the sum number of references from the stack and 
the continuation set. 

While $\gamma$ gives us a relation between the two respective heaps, we still need to know 
exactly how variables on the stack factor in this relationship. Let $l \in H_1$. 
Specifically, we need to know that the number of references to $l$ from every \emph{sub}value
in $V_1$ is equal to the size of the corresponding part of the class $\gamma(l)$.  
First, we need to access 
subvalues of a value using directions: 

\begin{definition}
	Let \ms{dir} be the set \{\ms{L},\ms{R},\ms{N}\}, denoting left, right, and next 
	respectively. We can index values via directions:
	\begin{align*}
		get_H(Just(\pairexcst{v_1}{v_2},\ms{L})) &= Just(v_1)\\
		get_H(Just(\pairexcst{v_1}{v_2},\ms{R})) &= Just(v_2)\\
		get_H(Just(\pairexcst{v_1}{v_2}),_) &= None\\
		get_H(Just(l),\ms{N}) &= Just(H(l)) \\
		get_H(Just(l), \_) &= None\\
		get_H(r,\_) &= r
	\end{align*}
	Let $P$ be a sequence of directions. Extend $get$ to sequence of directions:
	\begin{align*}
		find_H(v,D::P) &= find_H(get_H(v,D),P)\\
		find_H(v,[]) &= v
	\end{align*}
	Call $P$ valid w.r.t a value $v$ if $find_H(v,P) = Just (v')$ for some $v'$.
	Write $V_H(x;P)$ for $fromJust(find_H(V(x),P))$ given a valid sequence $P$ w.r.t $V(x)$,
	and $reach_H(V(x;P))$ for $reach_H(V_H(x;P))$.
	Given a map $m : X \to \mathcal{S}(\ms{dir})$ from varibles to valid sequences of directions, 
	Define $reachPath_{V,H}(X,m) = \biguplus_{x \in X} reach_H(V(x;m(x)))$.
\end{definition}

With this, the third condition gives us a more fined grained restriction: for any subvalue in $V_1$,
the number of references from it to $l$ is equal to the size of 
the intersection of the reachable set of the corresponding subvalue in $V_2$
with the appropriate class $\gamma(l)$ .

The next condition simply states that the continuation sets respect $\gamma$. Lastly, 
we have have that $F_1$ is greater $F_2$, with the overhead being exactly the sum 
$\sum_{l \in \gamma} |\gamma(l)| - 1$. 

\begin{definition} A configuration $(V,H,R,F)$ is well-formed if 
	$dom(H) \subseteq reach_H(V) \cup R \cup F$ and $reach_H(V) \subseteq dom(H)\setminus F$.
\end{definition}
Now the key lemma:

\begin{lemma}
	Let $(\mathcal{C}_2,e)$ be a linear computation. Given that 
	$\mathcal{C}_2 \vdash^{\mathsf{copy}} e \Downarrow v,H',F'$, and $H' \vDash v \mapsto a : A$, 
	for all well-formed configurations $\mathcal{C}_1$ such that $\mathcal{C}_1 \preceq \mathcal{C}_2$,
there is exists a triple
$(w,Y',M') \in \ms{Val} \times \ms{Heap} \times \ms{Loc}$ and 
	$\gamma' : dom(Y') \setminus M' \to \mathcal{P}(dom(H') \setminus F')$ s.t.
	\begin{enumerate}
			\item $\mathcal{C}_1 \vdash^{\mathsf{free}} e \Downarrow w,Y',M'$
			\item $\veq{H'}{Y'}{v}{w}$
			\item $\gamma'$ is a proper partition, such that for all $l \in dom(\gamma')$, 
				$|\gamma'(l)| = |reach_{Y_1}(w_1)(l)| + S(l)$
			\item For all $P$, $|reach_{H'}(find_{H'}(v;P)) \cap \gamma'(l)| = 
				reach_{Y'}(find_{Y'}(w;P))(l)$
			\item $\gamma'(l) \cap R = \gamma(l) \cap R$
			\item $|M'| = |F'| + |\oh{\gamma'}|$
	\end{enumerate}
\end{lemma}

The third condition deserves some explanation. The size of $\gamma(l)$ should equal the total number 
of ways $l$ could be reached from the root set in the \gcSem evaluation. This includes 
$reach_{Y_1}(w_1)(l)$ and $S(l)$, but also any paths to $l$ had been collected during the run 
(this accounts for unused variables that referenced $l$).

For a configuration $\mathcal{C} = (V,H,R,F)$, denote the current garbage w.r.t a set of root variables 
$X \subseteq dom(V)$ 
as $clean(\mathcal{C},X) = \{l \in H \mid l \notin F \cup R \cup reach_H(X)\}$. Some auxiliary lemmas: 

\begin{lemma}\label{itm:aux}
Let $V_2,H_2,R_2,F_2 \vdash^{\mathsf{copy}} e \Downarrow v,H',F'$, and 
$V_1,H_1,R_1,F_1 \preceq V_2,H_2,R_2,F_2$ because $(-,\gamma,\eta,-,-)$. Then the following hold:
\begin{enumerate}
\item for all $l \in dom(H_1) \setminus F_1$, 
$X \subseteq dom(V)$, $\gamma(l) \subseteq clean(\mathcal{C}_2,X)$ implies that 
$l \in clean(\mathcal{C}_1,X)$.
\end{enumerate}
\end{lemma}

Thus, we have shown that we can execute a computation using the 
\gcSem if the computation suceeded in a run with \copySem, and that indeed 
\copySem is an over approximation of \gcSem.

\textbf{Soundness of \copySem}
\label{sect:soundcopy}
To formally state the soundness theorem,
we need to introduce an auxiliary operational semantics (call this \ms{oper}) 
that does not use freelists or accounts for garbage collection. We use
it to characterize expressions that normalize to values when initialized with a sufficient 
freelist.  This technique was also employed in \cite{Hofmann:2003:SPH:604131.604148} 
to establish the soundness of their type system. The operational semantics consists of 
judgments of the following form, essentially a simplified version of the full cost semantics:

\[
\fbox{$V,H \vdash e \Downarrow v, H'$}
\]

This can be read as: under stack $V$, heap $H$ the expression $e$ evaluates to $v$, 
and engenders a new heap $H'$. The rules are entirely standard and are omitted here.
In $\ms{oper}$, the ``freelist'' is the whole ambient set of locations $\ms{Loc}$, 
thus we never run out of locations during evaluation. This introduces a problem when comparing 
evaluation results between a run with \copySem and $\ms{oper}$, as the return values 
might not be syntatically equal. Consider the following expression:

\begin{verbatim}
let _ = [4] in [5]
\end{verbatim}

Assuming locations are natural numbers, and we run \copySem with the freelist $\{1\}$. 
First, 1 is allocated and mapped to $\texttt{[4]}$. 
Then, since the first subexpression $\texttt{[4]}$ is not used afterwards, we collect 1, and reuse it
and map again to $\texttt{[5]}$. Thus the return value is 1.  In a run with $\ms{oper}$, 
we also first map 1 to $\texttt{[4]}$, but then 
allocate a new location, say 2, and map it to $\texttt{[5]}$, and the return value is 2. Due to the 
difference in allocation strategies and the fact that both are nondeterministic, we need a more 
robust notion of equality for values. Luckily, the structures from the denotational semantics 
does the job. In both runs, the return value maps to the semantic value $\texttt{[5]}$.
Thus semantical equality serves as the basis for context equivalence. 
Here we define it for contexts, which consisting of only the stack and heap. 
Later, we extend it the the full configuration. First, define value equivalence as
a shorthand for semantic equality: 

\begin{definition}[Value Equivalence]
Two values $v_1,v_2$ are equivalent (with the presupposition that they are well-formed w.r.t heaps $H_1,H_2$),
iff $H_1 \vDash v_1 \mapsto a : A$ and $H_2 \vDash v_2 \mapsto a : A$. 
Write value equivalence as $\veq{H_1}{H_2}{v_1}{v_2}$.
\end{definition}

\begin{definition}[Context Equivalence]
Two contexts $(V_1,H_1), (V_2,H_2)$ are equivalent
(with the presupposition that both are well-formed contexts) iff $dom(V_1) = dom(V_2)$ and 
for all $x \in dom(V_1)$, $\veq{H_1}{H_2}{V_1(x)}{V_2(x)}$. Write context equivalence as 
$\ctxeq{V_2,H_2}{V_2,H_2}$
\end{definition}

Stated simply, two contexts are equivalent when they have the same domain and equal variables bind 
equal semantic values. 


We are ready to state the soundness theorem now:

\begin{theorem}[Soundness]
\label{itm:soundness} let $H \vDash V : \Gamma$, $\Sigma; \Gamma \sststile{q'}{q} e : B$,
$V,H \; \vdash e \Downarrow v, H'$, and $H' \vDash v \mapsto a : A$.
Then $\forall C \in \mathbb{Q}^{+}$ and $\forall F,R \subseteq \ms{Loc}$,
if the following holds:
\begin{enumerate} 
\item $\wfc{V}{H}{R}{F}{e}$
\item $|F| \ge \Phi_{V,H}(\Gamma) + q + C$ 
\end{enumerate}
then there exists a context $(W,Y)$, a value $w$, and a freelist $F'$ s.t.
\begin{enumerate}
	\item $\ctxeq{W,Y}{V,H}$
  \item $W,Y,R,F \vdash e \Downarrow w, Y', F'$
	\item $\veq{H'}{Y'}{v}{w}$
  \item $|F'| \ge \Phi_{H'}(v:B) + q' + C$
\end{enumerate}
\end{theorem}

In other words, given a terminating expression (verified by succeeding with the run using \ms{oper})
and given a freelist that is sufficiently large (as predicated by the type derivation), 
a run with \copySem will normalize to an equivalent value, and the resulting freelist 
will be sufficiently large (as predicated by the type derivation).




%------------------------------------------------------------------------------


\section{Implementation}
\label{sect:implementation}

\jan{Implementation of analysis}
The garbage collection cost semantics is implemented as an alternative evaluation module inside
Resource Aware ML (RaML). As mentioned before, RaML leverages the syntax of OCaml programs. 
First, we take the OCaml type checked abstract syntax tree and perform a series of transformations. 
The evaluation modules operates on the resulting RaML syntax tree. 
In the gc evaluation module, \texttt{evaluate} has the following signature:

\begin{verbatim}
 evaluate : ('a, unit) Expressions.expression -> int -> (('a value * 'a heap * Int.Set.t) option) 
\end{verbatim}

Where the second argument \texttt{int} specifies the size of the initial freelist.
The result is a triple of the return value, heap, and freelist, or \texttt{None} 
in case the freelist was not sufficient for the evaluation.
Whereas the normal evaluation boxes every value (everything evaluates to a location), 
the gc module follows the cost semantics and only boxes data constructors. The rationale is
that the size for other values can be computed statically and stack allocated. One difference
between the cost semantics and its implementation is that while in the language presented here
list is the only data type, our implementation supports user defined data types. The extension
is straightforward except the treatment of the nil constructor, or generally ``empty'' constructors
that has arity zero. For simplicity of presentation, we evaluate all nil constructors to
the same null value in the cost semantics. This is natural for lists because all nil constructors 
are the same, and every list has at most one nil node. However, for custom data types that have 
more than one kind of empty constructor, it is not possible to map every constructor to the same 
null value. Thus, the implementation treats all constructors uniformly, so each nil constructor
also cost one heap location. 

As mentioned before, all functions used in a program are declared in a global mutually 
recursive block, and we do not account for the constant space overhead for this block in 
the cost semantics.  In order to implement this global function block, we allow closure creation
during program evaluation. However, we allocate all closures from a separate freelist into 
a separate heap.  This ensures that data constructors are allocated from the correct freelist 
and no space overhead is created by allocating closures for function declarations.

\textbf{Evaluation}
\label{sect:evaluation}
\begin{wraptable}{r}{0.5\textwidth}
	\vspace{-20pt}
		\begin{center}
	\begin{tabular}{l l}
		\hline
		\textit{\textbf{function}} & type \\ \hline
		quicksort & {[}'a -\textgreater 'a -\textgreater bool; 'a list{]} -\textgreater 'a list \\
		mergesort & {[}{[}'a; 'a{]} -\textgreater bool; 'a list{]} -\textgreater 'a list \\
		ocamlsort & {[}{[}'a; 'a{]} -\textgreater bool; 'a list{]} -\textgreater 'a list \\
		selection sort & int list -\textgreater int list \\
		eratosthenes & int list -\textgreater int list \\
		dfs & {[}btree; int{]} -\textgreater btree option \\
		bfs & {[}btree; int{]} -\textgreater btree option \\
		transpose & 'a list list -\textgreater 'a list list \\
		map\_it & {[}'a -\textgreater 'b; 'a list list{]} -\textgreater 'b list list * 'b list list \\
		pairs & 'a list -\textgreater ('a * 'a) list \\ \hline
	\end{tabular}
			\end{center}
				\vspace{-20pt}
			\caption{Signature of Test Functions}
		\vspace{-10pt}
\label{table:sig}
\end{wraptable}

\jan{discuss different cost metric used in eval}

We evaluated our new analysis on a number of functions (see \ref{table:sig}). 
The first table shows the type signature for each function. The second table presents the test 
data that
showcase the difference between the heap metric, the old analysis which only counts 
heap allocations, and the gc metric, which includes deallocations and copying cost for sharing.
For each metric, we show the heap space bound computed by RaML, its asymptotic behavior, 
the number of constraints generated, and the time elapsed during analysis. The last column gives
the expression for the exact heap high watermark derived by hand and verified by running the 
cost semantics.

Except for bfs and dfs, all functions in the table take a \emph{principal} argument of type list. 
The variables in the table refer to this argument (for example, the type of the 
principal argument of 
quicksort is 'a list). In general, M refers to the number of cons constructors of the principal 
argument (or the number of \emph{outer} cons nodes in case of nested lists); L refers to the
maximum number of cons nodes of the inner lists; N refers to the number of nil constructors.

For the sorting functions aside from mergesort, the new analysis using the gc metric
derived asymptotically better bounds when compared to the heap metric. Furthermore,
all bounds are \emph{exact} with respect to the cost semantics. In regards to mergesort, 
the analysis was not able to derive a tight bound due to the limitations of AARA in dealing 
with logarithmic bounds. A particularly nice result is that we can deduce for quicksort, 
the space usage is exactly 0, which justifies its use as a zero space-overhead sorting algorithm.

Next, we have have the graph search algorithms operating on a binary tree. Again, the gc metric
was able to derive exact space overheads, while the heap metric derived linear bounds for both.

For transpose, the gc metric derived an asymptotically better bound, but was not able to derive 
the exact overhead. We implement matrices as lists-of-lists in row-major order. 
The transpose function is implemented tail-recursively, with the accumulator starting as the 
empty list. When ``flipping'' the first row $r$ of the input and appending this to the accumulator, 
we need to create $|r|$ many new nil and cons constructors to store the row as a column. While this
overhead only occurs once, RaML is unable to infer this from the source code, and thus the cost
is repeated over the entire input matrix, resulting in the linear bound (w.r.t the size of the 
matrix). 

The last two functions demonstrate how the gc metric performs when there is variable sharing.
map\_it maps the input function across each list in the principal argument twice, returning a
tuple of nested lists. The gc metric dictates that every outer data constructor in the 
principal argument needs to be copied, and thus gives the linear bound M + N. In this case,
the bound is exact. The pairs functions takes a list and outputs a all pairs of the input list 
which are ordered ascending in input position. For example, 
pairs [1;2;3;4] = [(1,2);(1,3);(1,4);(2,3);(2.4);(3,4)]. For pairs, the gc metric derived a bound
that is asymptotically the same as the heap metric, but with better constants. An exact bound 
could not be derived because the deallocation potential from the pattern match in the 
definition of pairs is wasted because the matched body could already be typed with zero cost. 
However, this deallocation is used as usual in the cost semantics. Thus the slack in the bound 
totals to the size of the input. This example shows a weakness in the new gc metric and analysis; 
we discuss possible solutions and different approaches in the next sections. 




% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
\begin{table}[]
	\begin{adjustbox}{width=1.2\textwidth,center=\textwidth}
  \begin{tabular}{@{}llllllllll@{}}
		\toprule
		 & \multicolumn{4}{l}{heap metric} & \multicolumn{4}{l}{gc metric} &  \\ \midrule
		 \textit{\textbf{function}} & computed bound & asymptotic & constraints & time & computed bound & asymptotic & constraints & time & optimal \\
		 quicksort & 1.00 + 3.50*M + 1.50*M\textasciicircum{}2 & O(M\textasciicircum{}2) & 8515 & 0.52 & 0 & O(1) & 8519 & 0.48 & 0 \\
		 mergesort & 1.00 - 4.67*M + 6.33*M\textasciicircum{}2 & O(M\textasciicircum{}2) & 9572 & 0.64 & -0.50*M + 0.50*M\textasciicircum{}2 & O(M\textasciicircum{}2) & 9578 & 0.58 & \textbackslash{}floor(\textbackslash{}log(M)) \\
		 ocamlsort & 7.50 + 5.50*M + 1.00*M\textasciicircum{}2 & O(M\textasciicircum{}2) & 8565 & 0.51 & 1.00 + 1.00*M & O(M) & 8573 & 0.50 & M+1 \\
		 selection sort & 2.00 + 3.00*M + 1.00*M\textasciicircum{}2 & O(M\textasciicircum{}2) & 639 & 0.06 & 0 & O(1) & 642 & 0.05 & 0 \\
		 eratosthenes & 1.00 + 1.50*M + 0.50*M\textasciicircum{}2 & O(M\textasciicircum{}2) & 515 & 0.06 & 0 & O(1) & 517 & 0.04 & 0 \\
		 dfs & 3.00 + 2.00*M & O(M) & 5481 & 0.90 & 2 & O(1) & 5483 & 0.36 & 2 \\
		 bfs & 5.00 + 10.00*M & O(M) & 24737 & 4.15 & 4 & O(1) & 24742 & 1.62 & 4 \\
		 transpose & 1.00 + 3.50*L*M + 0.50*L*M\textasciicircum{}2 & O(L*M\textasciicircum{}2) & 10680 & 0.50 & 1.00 + 2.00*L*M & O(L*M) & 10684 & 0.50 & max(0,2*L-1) \\
		 map\_it & 2.00 + 2.00*L*M + 4.00*M & O(L*M) & 30699 & 1.58 & 1.00*M + 1.00*N & O(M+N) & 30703 & 1.57 & M + 1 \\
		 pairs & 1.00 + 1.00*M\textasciicircum{}2 & O(M\textasciicircum{}2) & 10214 & 0.60 & -0.50*M + 1.00*M*N + 0.50*M\textasciicircum{}2 & O(M\textasciicircum{}2+M*N) & 10217 & 0.64 & 0.5*M\textasciicircum{}2-1.5*M+2 \\
		  &  &  &  &  &  &  &  &  &  \\ \bottomrule
	\end{tabular}
	\end{adjustbox}
\end{table}

\section{Conclusion}
\label{sect:conclusion}

\jan{discuss function closures}

In this article, we introduced a novel operational cost semantics that models a perfect tracing 
garbage collector and an extension to AARA that is sound with respect to the new semantics.
We implemented the new semantics and analysis as modules in RaML and found through 
experimental testing that the extended AARA was able to derive asymptotically better bounds 
for several commonly used functions and programming patterns; often, the bounds are optimal 
with respect to the cost semantics.

One direction for future work is using the \emph{cost free} metric $\ms{cf}$ to model global garbage 
collection. In $\ms{cf}$, all resource constants, including constructor nodes, are set to 0.
A cost-free typing judgment then captures how an expression 
manipulates the structures in the context into the
the structure induced by its type. Using this fact, we are inspired to write the following rule:

\[
\inferr{
  \Sigma; \Gamma_1, \Gamma_2 \sststile{q'}{q} \irl{let}(e_1; x : \tau.e_2) : B
}{
  \Sigma; \Gamma_1 \sststile{p}{q} e_1 : A \\
  \Sigma; \Gamma_1 \sststile{}{\ms{cf}} e_1 : A' \\
  \Sigma; \Gamma_2, x : (A' - 1) \sststile{q'}{p} e_2 : B
}(\text{L:Let})
\]

Which states that to type a composition, we need to be able to type the first expression. 
Next, we note that instead of paying for every allocation in $e_1$, 
we only need to pay for the unit potenital for each constructor in the result $A$.
Thus we also type $e_1$ with the cost-free metric, so the result type $A'$
contains the same amount of potential as the context $\Gamma_1$, and pay for the 
constructors by removing unit potential from every node in $A$, and type $e_2$ with 
the resulting type $A'-1$. This cost-free composition rule would bring the type system closer 
to modeling the composition in the garbage collection cost semantics.

In \cite{Hoffmann:2015:ASC:2769448.2769449}, the authors have successfully employed this 
cost-free metric to analyze parallel programs. Here, the difficulty is showing
the simultaneous soundness of both destructive pattern matching and the cost-free composition. 
Another complication is the choice between local variable sharing and global context sharing.
We leave the exploration of this area to future work.

\jan{Use analysis for ocaml garbage collector}
\newpage
\label{sect:bib}
\bibliographystyle{plain}
%\bibliographystyle{alpha}
%\bibliographystyle{unsrt}
%\bibliographystyle{abbrv}
\bibliography{easychair,lit}

%------------------------------------------------------------------------------
\appendix

\section{Notation}
\label{sect:notation}
For a finite mapping $f : A \to B$, we write $dom$ for the defined values of $f$. Sometimes we shorten $x \in dom(f)$ to $x \in f$. We write $f[x \mapsto y]$ for the extension of $f$ where $x$ is mapped to $y$, with the constraint that $x \notin dom(f)$. 

Given possibly non-disjoint sets $A,B$, let the disjoint union be $A \oplus B$ defined by 
$\{(\ms{inl},a) \mid a \in A\} \cup \{(\ms{inr},b) \mid b \in B\}$.

Let a multiset be a function $S : A \to \mathbb{N}$, i.e. a map of the multiplicity of each element in the domain.  Write $x \in S$ iff $S(x) \ge 1$. If for all  $s \in S$, $\mu(s) = 1$, then $S$ 
is a property set, and we denote this by $\ms{set}(S)$. Addtionally, $A \uplus B$ denotes 
counting union of sets where $(A \uplus B) (s) = A (s) + B(s)$, similarly, 
$(A \cap B)(s) = \min{A(s),B(s)}$. Furthermore, $A \cup B$ denotes the usual union where 
$(A \cup B)(s) = \max{(A(s),B(s))}$.  For the union of disjoint multi-sets $A$ and $B$, 
we write $A \sqcup B$ to emphasize the disjointness.  For a collection of pairwise disjoint 
multi-sets $\mathcal{C}$, i.e. $\forall X,Y \in \mathcal{C}$. $X \cap Y = \emptyset$, we write $\dist{\mathcal{C}}$.

In the rest of the paper, 
we sometimes treat a set $A$ sets as multiset $A : A \to \mathbb{N}$ via 
$x \mapsto \begin{cases} 1 &\text{ if } x \in A \\0 &\text{ o.w.}\end{cases}$ when convenient. 
For instance, if an operation defined on multisets is used on sets and multisets, the set 
is thus promoted.

Given a set $A$, let $\mathcal{P}(A)$ be the powerset of $A$. Given a multiset $A$, let 
$\wp(A)$ be the power multiset of $A$, i.e. the set of all submultisets of $A$.

For a partition $f : A \to \mathcal{P}(B)$, we write the set of equivalence classes
as $ec(f) = \{f(x) \mid x \in A\} = f(A)$, i.e. the image of $f$ on its domain $A$.
Furthermore, a partition is \emph{proper} if for any $x \in A$, $f(x) \neq \emptyset$.

Given a proper partition $f : A \to \mathcal{P}(B)$, for every $a \in A$, 
we can choose an arbitrary 
$b \in f(a)$ to be the representative for that part; call this $rep(a)$.

\section{Linearity of Copy Semantics}

In the soundness proof of $\fogc$, we used an important lemma: that \copySem is 
semantically linear, i.e. locations are used linearly. 
To see why, consider the second premise in the rule L:MatL. In addition to the 
$p$ units of potential justified by the definition of linear potential, we get 1 unit 
from deallocating the cons cell itself. This is only sound if in the corresponding rule in 
\copySem a location was actually collected. Consider the evaluation in question:

\[
\infern{
  V(x) =  l\\
  H(l) = \pairexcst{v_h}{v_t} \\
	V'' = (V[x_h \mapsto v_h, x_t \mapsto v_t])\restriction_{FV(e_2)}\\
  g = \{l \in H \mid l \notin F \cup R \cup locs_{V'',H}(e_2)\}\\
  V'',H,R,F \cup g \; \vdash e_2 \Downarrow v, H',F' \\
}{
  V,H,R,F \; \vdash \listcaseexcst{x}{e_1}{x_h}{x_t}{e_2} \Downarrow v,H',F'
}
\]

If all the variables in $V$ was mapped to values with disjoint reachable sets, 
then we see that $l$ is only in the reachable set of $x$ (assuming that well-typed expressions
don't have duplicate occurences of variables, i.e. $x \notin FV(e_1) \cup FV(e_2)$. 
Then it follows that $l \in g$ given that locations in $V$, $R$, and $F$ are also all disjoint, 
and this is what we needed to justify the rule L:MatL.
Thus we have to show that \copySem preserves the linearity invariant: given a \emph{linear} 
computation, the evaluation result is also linear. 

First, we characterize semantically linear contexts: 

\begin{definition}(Linear context)
Given a context $(V,H)$, let
$x,y \in dom(V)$, $x \ne y$, and $r_x = reach_H(V(x))$, $r_y = reach_H(V(y))$.
	It is \emph{linear} given that:
\begin{enumerate}
\item $\ms{set}(r_x), \ms{set}(r_y)$
\item $r_x \cap r_y = \emptyset$
\end{enumerate}
Denote this by $\na{V,H}$.
\end{definition}

Whenever $\na{V,H}$ holds, visually, one can think of the 
stack as a collection of disjoint, directed trees with locations as nodes; 
consequently, there is at 
most one path from a variable on the stack $V$ to any location in $H$. Now we can 
formalize our intuition for linear computations: 

\begin{definition}[Linear computation]
Given a configuration $\mathcal{C} = (V,H,R,F)$ and an expression $e$, 
we say the 5-tuple $(\mathcal{C},e)$ is a \emph{computation}; it is a \emph{linear computation} 
given the following:
\begin{enumerate}
\item $dom(V) = FV(e)$
\item $\na{V,H}$
\item $\dist{\{R,F,locs_{V,H}(e)\}}$
\end{enumerate} 
And we write $\wfc{V}{H}{R}{F}{e}$ to denote this fact.
\end{definition}

% main lemma
The following lemma one of main results of this paper: given a semantically linear computation 
(one with no sharing between the underlying locations), the resulting value is linear 
(expressed by item 1. and 2. below):
\begin{lemma}[Linearity of \copySem]\label{itm:na}
For all stacks $V$ and heaps $H$, let  $V,H,R,F \; \vdash e \Downarrow v, H', F'$ 
and $\Sigma; \Gamma \vdash e : B$. Then given that $\wfc{V}{H}{R}{F}{e}$, we have the follwoing: 
\begin{enumerate}
\item $\ms{set}(reach_{H'}(v))$
\item $\dist{\{R,F',reach_{H'}(v)\}}$, and
\item $\stable{R,H,H'}$
\end{enumerate}
\end{lemma}

Where $\ms{stable}$ is a predicate on $\mathcal{P}(\ms{Loc}) \times \ms{Heap} \times \ms{Heap}$, defined
below. The premises of this lemma is a subset of the premises of the soundness theorem. 
Thus, we could have
merged the proof of this lemma directly into the soundness proof. However, we think makes the 
presentation clearer; furthermore, the linearity of \copySem is an interesting in itself, 
regardless of the accompanying type system. 

\begin{definition}[Stability]
Given heaps $H,H'$, a set of locations is \emph{stable} if $\forall l \in R$. $H(l) = H'(l)$. Denote this by
$\stable{R,H,H'}$.
\end{definition}

Define $\dagger :  L^p(A) \mapsto L(A)$ as the map that erases resource annotations. 
This gives a simplified jugdment \fbox{$\Sigma^{\dagger}; \Gamma^{\dagger} \vdash e : B^{\dagger}$}
used in proofs where the resource annotations are not necessary.

\begin{lemma}
\label{a} If $\Sigma; \Gamma \sststile{q'}{q} e : B$, then $\Sigma^{\dagger}; \Gamma^{\dagger} \vdash e : B^{\dagger}$.
\end{lemma}

\begin{proof}
Induction on the typing judgement.
\end{proof}

Define $FV^{\star} : \ms{Exp} \to \wp(\ms{Var})$, the multiset of free variables of expressions,
as the usual $FV$ inductively over the structure of $e$. This version of $FV$ reflects 
the multiplicity of variable occurences.

\begin{lemma}\label{itm:linear}
\label{a} If $\Sigma; \Gamma \sststile{q'}{q} e : B$, then $\set{FV^{\star}(e)}$ and $dom(\Gamma) = FV(e)$.
\end{lemma}

\begin{proof}
Induction on the typing judgement.
\end{proof}

\begin{lemma}\label{itm:stable}
Let $H \vDash v \mapsto a : A$. For all sets of locations $R$, if $reach_H(v) \subseteq R$ and $\stable{R,H,H'}$, then $H' \vDash v \mapsto a : A$ and $reach_H(v) = reach_{H'}(v)$.
\end{lemma}

\begin{proof}
Induction on the structure of $H \vDash v \mapsto a : A$.
\end{proof}

\begin{corollary}
Let $H \vDash V : \Gamma$. For all sets of locations $R$, if $\bigcup_{x \in V} reach_H(V(x)) \subseteq R$ and $\stable{R,H,H'}$, then $H' \vDash V : \Gamma$.
\end{corollary}

\begin{proof}
Follows from Lemma $\ref{itm:stable}$.
\end{proof}

% copy

\begin{lemma}[stability of copying]
	Let $H',v' = copy(H,L,v)$. For all $l \in H$, if $l \notin L$, then $H(l) = H'(l)$. 
	Further, $reach_{H'}(v') \subseteq L$.
\end{lemma}

\begin{lemma}[copy is copy]
	Let $H',v' = copy(H,L,v)$. If $H \vDash v \mapsto a : A$, then $H' \vDash v' \mapsto a : A$.
\end{lemma}


%------------------------------------------------------------------------------
% Index
%\printindex

%------------------------------------------------------------------------------
\end{document}


%%% Local Variables:
%%% mode: latex
%%% mode: flyspell
%%% TeX-master: t
%%% End:
