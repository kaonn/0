% easychair.tex,v 3.5 2017/03/15

\documentclass{easychair}
%\documentclass[EPiC]{easychair}
%\documentclass[EPiCempty]{easychair}
%\documentclass[debug]{easychair}
%\documentclass[verbose]{easychair}
%\documentclass[notimes]{easychair}
%\documentclass[withtimes]{easychair}
%\documentclass[a4paper]{easychair}
%\documentclass[letterpaper]{easychair}

\usepackage{doc}
\usepackage{fullpage}
\usepackage{latexsym}
\usepackage{verbatim}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{stackengine}
\usepackage{scalerel}
\usepackage{code,proof,amsthm,amssymb, amsmath}
\usepackage{mathpartir}
\usepackage{turnstile}
\usepackage{fancyvrb}
\usepackage{stmaryrd}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{booktabs}
\usepackage{adjustbox}
\usepackage{color}
\usepackage{wrapfig}
\usetikzlibrary{positioning} 

\allowdisplaybreaks

\input{../generic-defns}
\input{../syn-defns}
\input{../../pfpl/fun-defns}
\input{../../pfpl/pcf-defns}
\input{../../pfpl/prod-defns}
\input{../../pfpl/sum-defns}
\input{../../pfpl/icoi-defns}
\input{../../pfpl/t-defns}


% use this if you have a long article and want to create an index
% \usepackage{makeidx}

% In order to save space or manage large tables or figures in a
% landcape-like text, you can use the rotating and pdflscape
% packages. Uncomment the desired from the below.
%
% \usepackage{rotating}
% \usepackage{pdflscape}

% Some of our commands for this guide.
%
\newcommand{\easychair}{\textsf{easychair}}
\newcommand{\miktex}{MiK{\TeX}}
\newcommand{\texniccenter}{{\TeX}nicCenter}
\newcommand{\makefile}{\texttt{Makefile}}
\newcommand{\latexeditor}{LEd}

\newcommand{\myname}{Andrew Carnegie}
\newcommand{\myandrewid}{andrew}
\newcommand{\hwnumber}{1}
% =========================================================================== %

\newtheorem{theorem}{Theorem}

\newcommand{\ms}[1]{\ensuremath{\mathsf{#1}}}
\newcommand{\irl}[1]{\mathtt{#1}}
\newcounter{rule}
\setcounter{rule}{0}
\newcommand{\rn}
  {\addtocounter{rule}{1}(\arabic{rule})}	

\newcounter{infercount}
\setcounter{infercount}{1}
\newcommand{\infern}[2]{\inferrule{#1}{#2}(\text{S}_{\arabic{infercount}}\stepcounter{infercount})}
\newcommand*\ts[2]{%
  \,\scalebox{1}[0.5]{$\sststile[ss]{\textstyle#1}{\textstyle#2}$}\,
}
\newcommand{\inferr}[2]{\inferrule{#2}{#1}}
\newcommand{\inferrr}[3]{\inferrule[#1]{#2}{#3}}
\newcommand{\paircaseabt}[4]{\irl{match_P}(#2,#3.#4)}
\newcommand{\paircasecst}[4]{\irl{match} \; #1\; \{(#2;#3) \hookrightarrow #4\}}
\newcommand{\na}[1]{\mathsf{linear}(#1)}
\newcommand{\nr}[1]{\mathsf{no\_ref}(#1)}
\newcommand{\stable}[1]{\mathsf{stable}(#1)}
\newcommand{\set}[1]{\mathsf{set}(#1)}
\newcommand{\safe}[1]{\mathsf{safe}(#1)}
\newcommand{\dist}[1]{\mathsf{disjoint}(#1)}
\newcommand{\stack}[1]{\irl{stack}(#1)}
\newcommand{\denote}[1]{\llbracket#1\rrbracket}
\newcommand{\nil}{[]}
\newcommand{\cons}[2]{\pi(#1,#2)}
\newcommand{\sharecst}[4]{\irl{share}\;#1\;\irl{as}\;#2,#3\;\irl{in}\;#4}
\newcommand{\sharecpcst}[4]{\irl{share}\;#1\;\irl{as}\;#2,#3\;\irl{in}\;#4}
\newcommand{\shareabt}[4]{\irl{share}(#1;#2,#3.#4)}
\newcommand{\ssize}[2]{\left\Vert #2 \right\Vert_{#1}}
\newcommand{\card}[1]{card(#1)}
\newcommand{\val}[1]{\irl{val}(#1)}
\newcommand{\gc}[3]{\mathsf{gc}(#1,#2,#3)}
\newcommand{\wfc}[5]{\mathsf{linear}(#1,#2,#3,#4,#5)}
\newcommand{\veq}[4]{#3 \sim^{#1}_{#2} #4}
\newcommand{\ctxeq}[2]{(#1) \sim (#2)}
\newcommand{\oh}[1]{\oslash(#1)}
\newcommand{\fogc}{\ms{FO}^{gc}}
\newcommand{\jan}[1]{{\color{red} [\emph{Jan: #1}]}}
\newcommand{\yue}[1]{{\color{blue} [\emph{Yue: #1}]}}
\newcommand{\gcSem}{\ensuremath{\mathcal{E}_{\ms{gc}}}}
\newcommand{\copySem}{\ensuremath{\mathcal{E}_{\ms{copy}}}}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{attempt}{Attempt}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
%\makeindex

%% Front Matter
%%
% Regular title as in the article class.
%
\title{Automatic Space Bound Analysis for Functional Programs with Garbage Collection}

% Authors are joined by \and. Their affiliations are given by \inst, which indexes
% into the list defined using \institute
%
\author{
Yue Niu
\and
Jan Hoffmann
}

% Institutes for affiliations are also joined by \and,
\institute{
  Carnegie Mellon University,
  Pittsburgh, PA, United States\\
  \email{\{yuen,jhoffmann\}@cs.cmu.edu}
 }

%  \authorrunning{} has to be set for the shorter version of the authors' names;
% otherwise a warning will be rendered in the running heads. When processed by
% EasyChair, this command is mandatory: a document without \authorrunning
% will be rejected by EasyChair

\authorrunning{Niu and Hoffmann}

% \titlerunning{} has to be set to either the main title or its shorter
% version for the running heads. When processed by
% EasyChair, this command is mandatory: a document without \titlerunning
% will be rejected by EasyChair
\titlerunning{The {\easychair} Class File}

\begin{document}

\maketitle

\begin{abstract}
  This article introduces a novel system for deriving upper bounds on
  the heap-space requirements of functional programs with garbage
  collection.
  %
  The space cost model is based on a perfect garbage collector that
  immediately deallocates memory cells when they become unreachable.
  %
  Heap-space bounds are derived using type-based automatic amortized
  resource analysis (AARA), a template-based technique that
  efficiently reduces bound inference to linear programming.
  %
	The first technical contribution of the work is a new operational cost
  semantics that models a perfect garbage collector.
  %
  The second technical contribution is an extension of AARA
  to take into account automatic deallocation. A key observation is
  that deallocation of a perfect collector can be modeled with
  destructive pattern matching if data structures are used in a linear
  way. However, the analysis uses destructive pattern matching to
  accurately model deallocation even if data is shared.
  The soundness of the extended AARA with respect to the new cost semantics 
	is proven in two parts via an intermediate linear cost semantics.
  %
  The analysis and the cost semantics have been implemented as an
  extension to Resource Aware ML (RaML). An experimental evaluation
  shows that the system is able to derive tight symbolic heap-space
  bounds for common algorithms. Often the bounds are asymptotic
  improvements over bounds that RaML derives without taking into
  account garbage collection.
\end{abstract}

% The table of contents below is added for your convenience. Please do not use
% the table of contents if you are preparing your paper for publication in the
% EPiC Series or Kalpa Publications series

\iffalse
\setcounter{tocdepth}{3}
{\small
\tableofcontents}
\fi

%\section{To mention}
%
%Processing in EasyChair - number of pages.
%
%Examples of how EasyChair processes papers. Caveats (replacement of EC
%class, errors).

%------------------------------------------------------------------------------
\section{Introduction}
\label{sect:introduction}
The memory footprint of a program is an important performance metric
that determines if a program can be safely executed on a given
system. Ideally, developers should describe or approximate the memory
footprint of programs as functions of the inputs. However, such memory
bounds are often difficult to derive and to prove sound.
%
To assist programmers with deriving memory bounds, the programming
language community has developed automatic and semi-automatic analysis
techniques~\cite{Jost03,Chin08,Albert07b}
%
These systems are often special cases of more general resource bound
analyses that are based on abstract
interpretation~\cite{GulwaniMC09,BlancHHK10,SinnZV14},
recurrence
solving~\cite{FloresH14,AlbertFR15,DannerLR15,KincaidBBR2017}, type
systems~\cite{Jost10,HoffmannW15,LagoG11,CicekBGGH16,OOPSLA:WWC17,DasHP18},
program logics~\cite{Atkey10,CarbonneauxHZ15,CarbonneauxHRS17,Radicek17}, proof
assistants~\cite{Nipkow15,ChargueraudP15}, and term
rewriting~\cite{AvanziniM13,NoschinskiEG13,FrohnNHBG16}.

This article introduces a novel type system for automatically deriving
upper bounds on the heap-space requirements of functional programs
with garbage collection (GC).
%
Due to the challenges of modeling and predicting garbage collection,
most existing techniques for automating and guiding the derivation of
bounds on the heap memory requirements assume manual memory management
or simply ignore deallocation in the
analysis~\cite{Jost03,Jost06,SimoesVFJH12,Chin05,Chin08,Albert07b}. As
a result, the derived bounds are not accurate when the underlying
system employs garbage collection. The only exceptions we are aware of
are the works by Albert et al.~\cite{Albert09,Albert13}, by Braberman
et al.~\cite{Braberman08}, and by Unnikrishnan et
al.~\cite{UnnikrishnanSL03,Unnikrishnan09}. They analyze the
heap-space usage of programs with GC in two steps. First, they make
the deallocation of GC explicit; for example with a static analysis
for estimating object lifetimes~\cite{Albert13} or with a program
translation~\cite{Unnikrishnan09}. Second, they extract and solve
recurrence relations to derive a bound. The difference of our work is
that our technique is based on a type system, which is proved sound
with respect to a formal cost semantics. Advantages of a type-based
approach include natural compositionality and the use of type
derivations as certificates for resource bounds.

We model the (highwater mark) memory
usage based on a perfect garbage collector that immediately
deallocates memory cells when they become unreachable. The bounds that
are derived with for this cost model are not only a good theoretical
measure of the space complexity of the program but also have practical
relevance. Consider a function $f : A \to B$ and assume we derived a
bound $b_f : \denote{A} \to \mathbb{N}$. In an execution of $f(a)$, we
can then keep track of the memory usage and start the garbage
collector whenever the bound $b_f(a)$ is reached. It is then
guaranteed that the evaluation will succeed using $b_f(a)$ heap-memory
cells.\footnote{We are not considering memory fragmentation, which
  can be avoided using a copying collector.} To improve performance,
we could trigger GC more often (to compactify the heap) 
or allow memory use of more than $b_f(a)$ cells 
(to amortize the cost of garbage collection).

\emph{The first technical contribution} of the work is a new
operational cost semantics that models a perfect garbage collector.
%
The cost semantics is a big-step (or natural) semantics that keeps
track of the reachable memory cells in the style of Spoonhower et
al.~\cite{Spoonhower:2008:SPP:1411204.1411240} and
Minamide~\cite{DBLP:journals/entcs/Minamide99}. Operationally, this
cost is the highwater mark on the heap usage, or the maximum number of
cells used in the mutable store during evaluation. If we traverse the 
evaluation tree in preorder and view each node as a ``step'' 
of the computation, then a cell used in the current node
if they are reachable from the reminder of the
computation. Our formalization of reachability is identical with the
concept that garbage collectors implement to decide if a cell can be
freed during evaluation. For simplicity, we assume that evaluation of
cons node allocates one fresh heap cell and that all other
operations do not allocate heap cells. However, the semantics can be
instantiated with more realistic cost metrics. A difference to
existing formulations of cost semantics with
GC~\cite{Spoonhower:2008:SPP:1411204.1411240,DBLP:journals/entcs/Minamide99}
is that we update the highwater mark when reachability changes at
inner nodes of the derivation of the evaluation judgement instead of at
leaves. Moreover, we use a \emph{freelist}, which represents the
cells available for evaluation. This alternative formulation is
equivalent to the existing semantics and mainly motivated by the
soundness proof of our type system for bound analysis.  However, the
cost semantics is a natural approach and different enough from its
predecessors~\cite{Spoonhower:2008:SPP:1411204.1411240,DBLP:journals/entcs/Minamide99}
to be of interest in its own right.

\emph{Our second technical contribution} is the type system for
deriving bounds on the heap-space for programs with perfect GC. The
type system is an extension of type-based automatic amortized resource
analysis
(AARA)~\cite{Jost03,Jost10,VasconcelosJFH15,HoffmannAH10,HoffmannW15,NgoDFH16}. AARA
is a template-based technique that introduces potential functions to
efficiently automatically reduce bound inference to linear
programming. Existing type systems based on AARA can derive bounds on
the highwater mark of the heap usage for programs with manual
deallocation~\cite{Jost10}, but can only derive a bound on the number
number of total heap allocations for programs with
GC~\cite{HoffmannW15}. This is usually a gross over-approximation of
the actual memory requirement. Our extension is based on the
observation that deallocation of a perfect collector can be modeled
with destructive pattern matching (deallocate the matched cell) if
data structures are used in a linear way. In the type system, we
extend this observation to non-linear programs and use destructive
pattern matching to accurately model deallocation even if data is
shared.

\emph{The third technical contribution} is to prove the soundness of
the extended AARA with respect to the GC-based cost semantics. The
proof is non-trivial and proceeds in two parts: First, we prove the
soundness of the type system with respect to a semantics that copies
data structures if they are shared. Second, we prove for all programs
that our GC semantics uses less memory than this copying
semantics. While the proofs are relatively standard, many
details---like relating program states of the two semantics in the
simulation proof---are quite involved. Briefly, we have to provide and maintain 
a mapping $\gamma$ from the heap used in the GC semantics $H_{gc}$ to \emph{subsets} of
the heap used in the copying semantics $H_{copy}$ such that the image of 
$H_{gc}$ under $\gamma$ forms a partition on the second heap. The intuition is that 
given a cell $l \in H_{gc}$, there must be multiple cells $\gamma(l) \in H_{copy}$  
that are were allocated during sharing, and thus are ``morally the same'' as $l$.

The analysis and the cost semantics have been implemented as an
extension to Resource Aware ML (RaML)~\cite{HoffmannAH10,HoffmannW15}. RaML is an
implementation of AARA for a subset of OCaml that can derive
multivariate polynomial bounds. However, we restrict the technical
development in this paper to a simple first-order language with
tuples, lists, and trees. The proofs and ideas carry over the more
complex case of RaML.\footnote{An exception are function closures that
  we discuss in the Section~\ref{sect:conclusion}.}
%
An experimental evaluation shows that the system is able to derive
tight symbolic heap-space bounds for common algorithms. Our results
suggest that our new analysis provides asymptotic bound improvements
to several classes of commonly used functions and programming
patterns. We examine the reasons for these improvements and design
decisions throughout the system.



\section{Setting the Stage}
\label{sect:fop}

In the technical part of the paper, we focus our attention to a first-order, 
strictly evaluated functional language. 
You can think this language to be a simple subset of OCaml or SML. 
The only recursive data type in the language is the list type. 
However, our work extend to the expected algebraic data types definable in RaML.
Being first order, our language does not allow arbitrary local functional definitions. Instead,
all functions are defined at the top level and are mutually recursive by default.
The types of these functions form a signature for the program, and the semantics and typing 
judgments will be indexed by this signature.
Thus, the function types of the language can be expressed 
as arrows between zero-order (base)  types. 
%
Types are formally defined in Figure~\ref{fig:exp}. Like in all
grammars, we provide the abstract (left) and concrete (right) syntax
for every type former.\jan{cite pfpl}
A \emph{signature}  $\Sigma : \ms{Var} \to \ms{FTypes}$ is a map from variables to 
first-order types. 
A \emph{program} $P$ is a $\Sigma$ indexed map from $\ms{Var}$ to pairs 
$(y_f,e_f)_{f \in \Sigma}$, where $\Sigma(y_f) = \tau \to \tau'$, 
and $\Sigma;y_f : \tau \vdash e_f : \tau'$ (the type system is discussed in Section~$\ref{sect:typing}$). 
We write $P : \Sigma$ to mean $P$ is a program with signature $\Sigma$. 

\begin{figure}[t!]
\vspace{-2ex}
\begin{minipage}[t]{0.33\linewidth}
	\[
\begin{array}{r l l l l}
\hspace{-1em}\ms{BTypes} & \tau \,\,\,\,\, ::= \\
	& \irl{nat}                	 			& \irl{nat}											\\
	& \unittyabt                	 			& \unittycst								\\
  & \booltyabt                       & \booltycst                \\
  & \prodtyabt{\tau_1}{\tau_2}       & \prodtycst{\tau_1}{\tau_2}\\
  &\listtyabt{\tau}		& L(\tau)				\\						
  \\
\hspace{-1em}\ms{FTypes} & \rho \,\,\,\,\, ::= \\
	&\irl{arr}(\tau_1;\tau_2) 				& \arrtycst{\tau_1}{\tau_2}\\ 	
\\
\ms{Val}
        & v   \,\,\,\,\, ::= \\
 	& \irl{val}(n)                                			& n 											\\	
 	& \irl{val}(\irl{T})                               			& \irl{T} 								 \\ 
 	& \irl{val}(\irl{F})                                			& \irl{F}								 \\ 
 	& \irl{val}(\irl{Null})                                  & \irl{Null} 								 \\ 
 	& \irl{val}(l)                                			& l 								 \\ 
 	& \irl{val}(\pairexabt{v_1}{v_2})                             & \pairexcst{v_1}{v_2} 					
% \ms{Loc} & l   \,\,\,\,\, ::= \\
%  	& \irl{loc}(l)                                		\\	\\
% \ms{Var} & x   \,\,\,\,\, ::= \\
%  	& \irl{var}(x)                                		\\	
\end{array}
\]
\end{minipage}
\hfill
\begin{minipage}[t]{0.59\linewidth}
\[
\begin{array}{r l l l}
\ms{Exp}
        & e   \,\,\,\,\, ::= \\
 	& \irl{var}(x)                                			& x 											\\	
  & \irl{nat}[n]							& \numeral{n}											\\	
  & \irl{unit}							& ()											\\	
  & \irl{T}							& \irl{T}											\\	
  & \irl{F}	   					& \irl{F}											\\	
  & \ifexabt{x}{e_1}{e_2} & \ifexcst{x}{e_1}{e_2} \\ 
  % & \irl{lam}(x:\tau.e) 						&\lambda \; x : \tau. e 	\\	
  & \irl{ap}(f;x) 					& \appcst{f}{x} 									\\	
  & \irl{tpl}(x_1;x_2)     	& \pairexcst{x_1}{x_2}                								\\	
 	& \paircaseabt{p}{x_1}{x_2}{e_1}					& \paircasecst{p}{x_1}{x_2}{e_1}   \\	
 	& \nilexabt					& []   									\\	
 	& \consexabt{x_1}{x_2}					& x_1::x_2   									\\	
 	& \listcaseexabt{l}{e_1}{x}{xs}{e_2}					& \listcaseexcst{l}{e_1}{x}{xs}{e_2}   \\	
  & \irl{let}(e_1; x : \tau.e_2)			& \irl{let}\; x = e_1 \; \irl{in}\; e_2   \\	
  & \shareabt{x}{x_1}{x_2}{e} &\sharecst{x}{x_1}{x_2}{e}\\ 
\end{array}
\]
\end{minipage}

	\caption{Simple Types, Values, and Expressions }
\label{fig:exp}
\end{figure}

To simplify the presentation, the expressions of our language (see Figure~\ref{fig:exp}) are in \emph{let normal form} (also \emph{A normal form}).
% We allow an extended syntax in the implementation. 
The one nonstandard construct is $\sharecst{x}{x_1}{x_2}{e}$, which we will explain in more 
detail in the following sections. We introduce two distinct notions of \emph{linearity}, one on 
the syntactic level, and one on the semantic level. Syntactic linearity is linearity in 
expression variables, while semantic linearity is linearity in locations (defined below).
We say that a semantics is linear if it respects semantic linearity.

In line with previous works on space cost
semantics~\cite{Spoonhower:2008:SPP:1411204.1411240,DBLP:journals/entcs/Minamide99},
we employ a heap, which persistently binds
locations to values (normalized terms).  As usual, we derive the cost
of a program from the number of heap locations 
used during execution. Locations is an infinite set of names
for addressing the heap.
%
For the rest of the paper, we use the following:
$\ms{Stack} \triangleq \{ V \mid V : \ms{Var} \to \ms{Val} \}$
and $\ms{Heap} \triangleq \{ H \mid H: \ms{Loc} \to \ms{Val} \}$
for the set of stacks and heaps respectively. 

\textbf{Reachability}
\label{sect:reachability}
Before we define the rules for the cost semantics, we relate the heap locations to 
values with the 3-place reachability relation $reach(H,v,L)$ on $\ms{Heap} \times \ms{Val} \times \wp(\ms{Loc})$, where $\wp$ is the powermultiset. 
This is read as ``under heap $H$, the value $v$ reaches the multiset 
of locations $L$''. 
Write $L = reach_H(v)$ to indicate this is a functional relation 
justified by the (valid) mode $(+,+,-)$. We also say that the reachable set of $v$ is $L$. 
%
\begin{mathpar}
\inferrule{
	A = reach_H(v_1)\\
	B = reach_H(v_2)
}{
	A \uplus B = reach_H(\pairexcst{v_1}{v_2}) 
} 

\inferrule{
	A = reach_H(H(l))\\
}{
	\{l\} \uplus A = reach_H(l)
} 

\inferrule{
	v \in \mathbb{N} \cup \{\irl{T},\irl{F},\irl{Null}\}
}{
	\emptyset = reach_H(v)
} 
\end{mathpar}
%
In the rules, $\uplus$ is multiset union. For the rest of the paper, we will sometimes mix 
multiset and set operations as the situation calls for. For example, we will write 
$l \in S$ for a multiset $S$ if $S(l) \ge 1$. Complete definitions and notations can
be found in the appendix.

The notion of reachability naturally lifts to expressions:
\begin{align*}
  &locs_{V,H}(e) = \biguplus\limits_{x \in FV(e)} reach_H(V(x))
\end{align*}
Where $FV : \ms{Exp} \to \mathcal{P}(\ms{Var})$ denotes the set of free-variables of expressions as usual.\\

\textbf{Towards the Garbage Collection Cost Semantics}
Now we are ready to give a first attempt to modeling the cost semantics for a
tracing garbage collector. Before we present our new semantics, we explain an
existing cost semantics we experimented with~\cite{DBLP:journals/entcs/Minamide99}. Judgements have the form
%
$V,H,R \vdash e \Downarrow^s v,H$,
%
which can be read as follows. Under stack $V \in \ms{Stack}$, heap $H \in \ms{Heap}$, 
and continuation set $R \subseteq \ms{Loc}$, $e$ evaluates to $v$ 
and $H'$ using $s$ heap locations. The idea is that $R$ keeps track of the set of locations 
necessary to complete the evaluation \emph{after} $e$ is evaluated (hence the name continuation).
For example, we have the let rule: 
%
\[
	\inferrule{
		V,H,R \uplus locs_{V,H}(x.e_2) \vdash e_1 \Downarrow^{s_1} v_1,H_1\\
		V[x \mapsto v_1],H,R \vdash e_2 \Downarrow^{s_2} v_2,H_2\\
	}{
		V,H,R \vdash \irl{let}(e_1; x : \tau.e_2) \Downarrow^{\max{s_1,s_2}} v_2,H_2
	}
\]

Notice that to evaluate $e_1$, we have to extend the continuation $R$ with locations in $e_2$, which
will be used \emph{after} $e_1$ is evaluated. The total space used is the max of the 
component, indicating that locations used for $e_1$ can be reused for $e_2$. 
This is clear when we look at the variable rule. 
%
\[
	\inferrule{
		V(x) = v
		}{
			V,H,R \vdash x \Downarrow^{|dom(R \uplus reach_H(v))|} v,H
			}
\]
%
It states that evaluating a variable $x$ requires the locations reachable from $x$ as well as 
the continuation set $R$. While this way of counting heap locations does model a tracing garbage 
collector, it is not compatible with the existing type systems for amortized analysis. In these
systems, the type rules count the heap locations as data is created, i.e.\ at each data constructor.
Thus looking up a variable incurs no cost, since it was accounted for during creation. This mismatch
between the dynamics and statics of language prevents us from proving the soundness of the analysis. 

%------------------------------------------------------------------------------

\section{Garbage Collection Cost Semantics}
\label{sect:semantics}

In this section, we present our novel cost semantics by combining
\emph{freelist semantics} from~\cite{Hofmann:2003:SPH:604131.604148}
with the cost semantics for modeling perfect
GC~\cite{DBLP:journals/entcs/Minamide99} that we discussed in the
previous section. The resulting semantics, called \gcSem, is well suited for
proving the soundness of the novel type-based bound analysis.

The garbage collection cost semantics \gcSem{} is defined by a collection of judgement of the form
\[
\mathcal{C} \; \vdash_{P : \Sigma} e \Downarrow v, H', F'
\]

Where $\mathcal{C} \in \ms{Stack} \times \ms{Heap} \times
\mathcal{P}(\ms{Loc}) \times \mathcal{P}(\ms{Loc})$ is a \emph{configuration}
usually written with variables $V,H,R,F$. 
Because the signature $\Sigma$ for the mapping of function names to first-order functions 
does not change during evaluation, we drop the subscript $P:\Sigma$ from $\vdash_{P:\Sigma}$ 
when the context of evaluation is clear. Given a configuration $\mathcal{C} = (V,H,R,F)$,
the evaluation judgment states that under stack $V$, heap $H$, continuation set $R$,
freelist $F$, and program $P$ with signature $\Sigma$, the expression $e$ evaluates to value $v$, 
and engenders a new heap $H'$ and freelist $F'$. In comparison with the attempt from 
the previous section, the key ingredient we added is the freelist, which serves 
as the set of available locations.

The semantics \gcSem{} is to designed to model the heap usage of a program running with a 
tracing counting garbage collector: whenever a heap cell becomes unreachable from the 
root set, it becomes collected and added to the freelist as available for reallocation.
As before, the continuation set $R$ represents the set of locations 
required to compute the continuation \emph{excluding} the current expression.
We define the  \emph{root set} as the union of the locations in the continuation set $R$ 
and the locations in the current expression $e$. 

The inference rules for the semantics are given in Figure~\ref{fig:costsem}.
For example, the rule F:CondT states that, to evaluate a conditional, 
look in the stack for the value of the branching boolean.
In the case it is true, we proceed to evaluate the first branch. This update is only necessary 
to prove properties about the evaluation, and is not needed in an implementation.
Furthermore, we collect cells in the heap
that are not reachable from the root set ($R \cup locs_{V,H}(e_1)$) 
or already in the current free-list
$F$, and add them ($g$) to the available cells for evaluating $e_1$. 

Another example is the rule F:Let for let expressions:
to evaluate the expressions $\irl{let}(e_1; x {:} \tau.e_2)$, we evaluate the first 
expression with the corresponding restricted stack $V_1$ and a expanded continuation set $R'$. 
The extra locations come from the free variables of $e_2$ (not including the bound variable $x$),
which we cannot collect during the evaluation of $e_1$. Next, we extend the restricted stack 
$V_2$ with the result $v_1$, and evaluate $e_2$ with this stack and the original continuation 
set $R$. The other rules are similar. 

\begin{figure}[t!]
  \centering
\small
\begin{mathpar}
\infern{
	V_1 = V\restriction_{FV(e_1)}\\
  R' = R \cup locs_{V_2,H}(\irl{lam}(x : \tau.e_2))\\
  V_1,H,R',F \vdash e_1 \Downarrow v_1,H_1,F_1\\
	V_2' = (V[x \mapsto v_1])\restriction_{FV(e_2)}\\
  g = \{ l \in H_1 \mid l \notin F_1 \cup R \cup locs_{V_2',H_1}(e_2) \}\\
  V_2',H_1,R, F_1 \cup g \vdash e_2 \Downarrow v_2,H_2,F_2 \\
}{
  V,H,R,F \; \vdash \irl{let}(e_1; x : \tau.e_2) \Downarrow v_2,H_2,F_2
}

\infern{
  V(x) = \irl{T}\\
  g = \{l \in H \mid l \notin F \cup R \cup locs_{V,H}(e_1)\}\\
	V' = V\restriction_{FV(e_1)}\\
  V',H,R,F \cup g\; \vdash e_1 \Downarrow v, H',F'
}{
  V,H,R,F \; \vdash \ifexabt{x}{e_1}{e_2} \Downarrow v, H',F'
}

\infern{
	V(x) = \irl{F}\\
  g = \{l \in H \mid l \notin F \cup R \cup locs_{V,H}(e_2)\}\\
	V' = V\restriction_{FV(e_2)}\\
  V',H,R,F \cup g \; \vdash e_2 \Downarrow v, H',F'
}{
  V,H,R,F \; \vdash \ifexabt{x}{e_1}{e_2} \Downarrow v, H' ,F'
}

% function

\infern{
  V(x) = v'\\
  P(f) = (y_f,e_f)\\
  g = \{l \in H \mid l \notin F \cup R \cup locs_{V,H}(e_f)\}\\
  [y_f \mapsto v'],H,R,F \cup g \; \vdash e_f \Downarrow v,H',F'\\
}{
  V,H,R,F \; \vdash \appcst{f}{x} \Downarrow v,H',F'
}

% lists

\infern{
}{
  V,H,R,F \; \vdash \nilexabt \Downarrow \irl{val(Null)},H,F
} 

\infern{
  v = \pairexcst{V(x_1)}{V(x_2)}\\
	l \in F\\
  H' = H\{l \mapsto v\}
}{
	V,H,R,F \; \vdash \consexcst{x_1}{x_2} \Downarrow l,H' ,F \setminus \{l\}
}



\infern{
  V(x) = \irl{Null}\\
	V' = V\restriction_{FV(e_1)}\\
  g = \{l \in H \mid l \notin F \cup R \cup locs_{V,H}(e_1)\}\\
  V',H,R,F \cup g \; \vdash e_1 \Downarrow v, H',F' \\
}{
  V,H,R,F \; \vdash \listcaseexcst{x}{e_1}{x_h}{x_t}{e_2} \Downarrow v,H',F'
}

\infern
{ V(x) = v\\
}
{V,H,R,F \; \vdash x \Downarrow v,H,F}

\infern{
  V(x) =  l\\
  H(l) = \pairexcst{v_h}{v_t} \\
	V'' = (V[x_h \mapsto v_h, x_t \mapsto v_t])\restriction_{FV(e_2)}\\
  g = \{l \in H \mid l \notin F \cup R \cup locs_{V'',H}(e_2)\}\\
  V'',H,R,F \cup g \; \vdash e_2 \Downarrow v, H',F' \\
}{
  V,H,R,F \; \vdash \listcaseexcst{x}{e_1}{x_h}{x_t}{e_2} \Downarrow v,H',F'
}


\inferr{
  V,H,R,F \; \vdash \sharecst{x}{x_1}{x_2}{e} \Downarrow v,H'',F'
}{
  V = V'[x \mapsto v']\\
  V'[x_1 \mapsto v',x_2 \mapsto v'],H',R,F \; \vdash e \Downarrow v,H'',F'
}(\text{F:Share})
\end{mathpar}
  \caption{Cost Semantics for Perfect Garbage Collection}
  \label{fig:costsem}
\end{figure}
Note that in contrast to the semantics in the previous section, evaluating a variable does not incur
any cost. This ensures that we will be able prove the soundness of the type system. 
Also, since we don't allow local function definitions, we do not create closures
during evaluation. % However, our implementation uses closures to implement the global block of 
% function definitions.
Also note that we restrict the domain of
the stack to the appropriate variables during evaluation. This is only
to facilitate the proof of the linearity of the copying semantics introduced later, and not
necessary for the implementation. These issues are discussed in
\ref{sect:implementation}.

\begin{wrapfigure}{r}{0.5\textwidth}
	\vspace{-20pt}
		\begin{center}
\begin{verbatim}
let rec append (l1, l2) =
  match l1 with
    | [] -> l2
		| x::xs -> x::(append (xs, l2))

let rec appendTwice l = 
	share l as l1,l2 in
	let l1' = append (l1, []) in 
	let l2' = append (l2, []) in 
	(l1',l2')
\end{verbatim}
			\end{center}
				\vspace{-20pt}
			\caption{dfs algorithm}
		\vspace{-10pt}
\label{fig:dfs}
\end{wrapfigure}

For example, we can implement the \texttt{append} and \texttt{appendTwice} function, 
which has variable sharing. First, we analyze the heap usage of \texttt{append} under 
\gcSem{}. We case on the first component of the input. In case it's nil, 
we just return \texttt{l2}, and there are no allocations or deallocations. In case it's
cons of \texttt{x} and \texttt{xs}, we need to allocate one heap location for the
cons cell binding \texttt{x} 
and the recursive result, for which we can use the just matched-on cell. Again, 
the net overhead is zero. Thus, the total space overhead of \texttt{append} is zero.
For \texttt{appendTwice}, we first share the list \texttt{l} as \texttt{l1} and 
\texttt{l2}. In the first \texttt{let}, the locations in \texttt{l2} are added to the
continuation set, which prevents the 
first call to \texttt{append} from destructing \texttt{l1}. Thus size of \texttt{l1} 
new locations are allocated from the freelist to construct \texttt{l1'}. 
The second call has no net increase in heap allocations since \texttt{l2} can be 
destructed along the way. 
The return value is a pair which is stack-allocated and doesn't require a heap 
allocation. Thus, the total space overhead for \texttt{appendTwice} 
is size of input list \texttt{l}.

From this, we see that the minimum size for the initial freelist to successively evaluate 
a call to \texttt{appendTwice} is exactly the length of the input. In general, we 
define the cost of a closed program to be the minimum size of the initial freelist that
guarantees successful evaluation. Although we don't prove it in this paper, this can be seen
to be equivalent to the cost annotation in previous cost semantics introduced in 
section~\ref{sect:fop}, which justifies \gcSem{} as a cost semantics.

\section{Automatic Amortized Heap-Space Analysis with GC}
\label{sect:aara}

{\bf Automatic Amortized Resource Analysis (AARA)}
%
The idea of AARA~\cite{Jost03,Jost10,HoffmannAH10,HoffmannW15} is to automate the potential method of amortized
analysis using a type system.  Types introduce potential function that
map data structures of the given type to non-negative numbers. The
type rules ensure that there is always sufficient potential to cover
the evaluation cost of the next step and the potential of the
next program state.

To illustrate the idea, we informally explain the linear potential method for the dfs algorithm in Figure~\ref{fig:dfs}
We will use the allocation/heap metric which simply counts the number of cons constructor calls during the evaluation.%
\footnote{This is in contrast to the highwater mark for the GC semantics \gcSem{} that is targeted by our new analysis.}
With this metric, the cost of evaluating $\text{dfs}(t,n)$ is $2m+3$, where $m$ is the number 
of \texttt{Node} constructors in the input.
%

\yue{1) what's the cost of append and appendTwice with the metric ?}

\yue{2) what are the types of the functions in aara? what do they intuitively mean?}

\yue{3} how does sharing work in appendTwice? What are the types of the variables in the code? (need to add potential)

\yue{4) how do we derive the types automatically? (I can write that later)}

\jan{Better intro for AARA, polynomial potential somewhere}

\textbf{Linear Potential Functions}
Before giving the type rules, we need to formalize linear potential as explained above.
Since potential is associated with the \emph{structure} of a value and not the particular heap 
locations, we it is helpful to introduce a mapping from
heap values to semantic values of a type. 
First give a denotational semantics for (define the structures of) the first-order types: 
  \begin{minipage}{0.4\linewidth}
\begin{align*}
	\denote{\unittyabt} &= \{\val{\irl{Null}}\}\\
	\denote{\booltyabt} &= \{\val{\irl{T}}, \val{\irl{F}}\}\\
	\denote{\irl{nat}} &= \mathbb{N}\\
\end{align*}
  \end{minipage}%
\begin{minipage}{0.6\linewidth}
\begin{align*}
\pairexcst{a_1}{a_2} &\in \denote{\prodtycst{A_1}{A_2}} 
	\text{ if } a_1 \in \denote{A_1} \text{ and } a_2 \in \denote{A_2}\\
\nilexcst &\in \denote{L(A)}\\
\consexcst{a}{l} &\in \denote{L(A)} \text{ if } a \in \denote{A} \text{ and } l \in \denote{L(A)}\\
\end{align*}
  \end{minipage}\\
The set for each type is the least set such that the above holds. As usual, we write $[a_1,...,a_n]$ for $\consexcst(a_1,...,\consexcst(a_n,\nilexcst))$. \yue{something wrong with these cons's.}

\begin{figure}[t!]
  \centering
  \footnotesize
  \begin{minipage}{1.04\linewidth}
\begin{mathpar}
\inferr{
  H \vDash \val{n} \mapsto n : \irl{nat}
}{
  n \in \mathbb{Z}
}(\text{V:ConstI})

\inferr{
	H \vDash \val{\irl{Null}} \mapsto \val{\irl{Null}} : \unittyabt
}{
}(\text{V:ConstI})

\inferr{
  H \vDash \val{\irl{Null}} \mapsto \val{\irl{Null}} : L(A)
}{
  A \in \ms{BType}
}(\text{V:Nil})

\inferr{
  H \vDash \val{\irl{T}} \mapsto  \val{\irl{T}} : \booltyabt
}{
}(\text{V:True})

\inferr{
  H \vDash \val{\irl{F}} \mapsto \val{\irl{F}}  : \booltyabt
}{
}(\text{V:False})

	\inferr{
		H \vDash \pairexcst{v_1}{v_2} \mapsto \pairexcst{a_1}{a_2} : \prodtycst{A_1}{A_2}
	}{
		H \vDash v_1 \mapsto a_1 : A_1 \\
		H \vDash v_2 \mapsto a_2 : A_2
	}(\text{V:Pair})
	
\inferr{
  H \vDash l \mapsto [a_1,\ldots,a_n] : L(A)
}{
  l \in \ms{Loc}\\
  H(l) = \pairexcst{v_h}{v_t}\\
  H \vDash v_h \mapsto a_1 : A\\
  H \vDash v_t \mapsto [a_2,\ldots,a_n] : L(A)
}(\text{V:Cons})
\end{mathpar}
  \end{minipage}
  \caption{Mapping Locations to Semantic Values}
  \label{fig:semVal}
\end{figure}

In Figure~\ref{fig:semVal} we give the judgements relating heap values to semantic values, in the form \fbox{$H \vDash v \mapsto a : A$}, which can be read as follows: Under heap $H$, heap value $v$ defines the semantic value $a \in \denote{A}$.  
%
Given a stack $V$, we write $H \vDash V : \Gamma$ if $dom(V) = dom(\Gamma)$ and
for every $x : A \in \Gamma$, $H \vDash V(x) \mapsto a : A$ for some $a \in \llbracket A \rrbracket$.

We introduce linear potential for structures corresponding to the base types. The definition of
linear potential is standard~\cite{Hoffmann11}. Below is the grammar for resource-annotated types:
%
\[
\begin{array}{r l l l c r l l l}
\ms{BTypes} & A \,\,\,\,\, ::= &  \hspace{8em}     &  & \ms{FTypes} & \rho \,\,\,\,\, ::= \\
	& \ldots &    & & 	 &\irl{arr}(A_1;A_2;p;q) 				& A_1 \xrightarrow{p/q} A_2\\ 	
	&\irl{list}^p(A)		& L^p(A)		
\end{array}
\]
%
The intended meaning is that a list of $L^p(\tau)$ has $p$ units of potential per 
cons cell, and a functions of type $\tau_1 \xrightarrow{p/q} \tau_2$ takes constant potential 
$p$ to run and $q$ is the constant potential left afterwards.

With linear potential, each component of a structure is associated with a constant amount of 
potential.  Given a structure $a$ in a heap $H$, where  $H \vDash v \mapsto a : A$, we define 
its potential $\Phi_H(a : A)$ by recursion on $A$: 
%
\begin{align*}
&\Phi_H(a : A) = 0 &A \in \{\unittycst, \booltyabt, \irl{nat}\}\\
&\Phi_H(\pairexcst{a_1}{a_2} : \prodtycst{A_1}{A_2}) = \Phi_H(a_1 : A_1) + \Phi_H(a_2 : A_2)\\
&\Phi_H([a_1,...a_n] : L^p(A)) = p\cdot n + \sum_{1 \le i \le n} \Phi_H(a_i : A)  
\end{align*}
%
Now define $A \curlyvee A_1,A_2,n$ as the sharing relation for resource-annotated types:
\begin{align*}
	&L^p(A) \curlyvee^n L^q(A_1),L^r(A_2) & \text{if } p = q + r + n \;\text{and}\; 
			A \curlyvee^n A_1,A_2\\
	&\prodtycst{A}{B} \curlyvee^n \prodtycst{A_1}{B_1}, \prodtycst{A_2}{B_2}
		&\text{ if } A \curlyvee^n A_1,A_2 \text{ and } B \curlyvee^n B_1,B_2\\
	&A \curlyvee^n  A,A& \text{ if } A \in \{\unittycst, \booltycst, \irl{nat}\}
\end{align*}
The sharing relation captures the amount of potential needed to copy a type $A$ where each 
cons node in any structure in $\llbracket A \rrbracket$ has a copying overhead $n$.

\textbf{Type Rules}
\label{sect:typing}
The type system $\fogc$ consists of rules of the form \fbox{$\Sigma;\Gamma \sststile{q'}{q} e : A$}, 
read as under signature $\Sigma : \ms{Var} \to \ms{FTypes}$, 
context $\Gamma : \ms{Var} \to \ms{BTypes}$, $e$ has type $A$ starting with $q$ units of 
constant potential and ending with $q'$ units.

Our type system is based on the one of classic linear AARA~\cite{Jost03}. 
We give a review of the rules in Figure~\ref{fig:typeRules}.
Since we are interested in the number of heap locations, 
there is an implicit side condition in all rules
which ensures all constants are assumed to be nonnegative.
\yue{explain the cons, match, and share rules briefly}

\begin{figure}[t!]
  \centering
\small
\begin{mathpar}
\inferr{
  \Sigma; x : B \sststile{q}{q} x : B
}{
}(\text{L:Var})

\inferr{
  \Sigma; x : A \sststile{q'}{q} f(x) : B
}
{
  \Sigma(f) = A \xmapsto{q/q'} B
}

\inferr{
  \Sigma; \Gamma, x : \irl{bool} \sststile{q'}{q} \ifexcst{x}{e_t}{e_f} : B
}{
  \Sigma; \Gamma \sststile{q'}{q} e_t : B \\
  \Sigma; \Gamma \sststile{q'}{q} e_f : B
}(\text{L:Cond})

\inferr{
  \Sigma; x_1 : A_1, x_2 : A_2 \sststile{q}{q} \pairexcst{x_1}{x_2} : \prodtycst{A_1}{A_2}
}{
}(\text{L:Pair})

\inferr{
  \Sigma; \Gamma, x : (A_1,A_2) \sststile{q'}{q} \paircasecst{x}{x_1}{x_2}{e} : B
}{
  \Sigma; \Gamma, x_1 : A_1, x_2 : A_2 \sststile{q'}{q} e : B
}(\text{L:MatP})

\inferr{
  \Sigma; \emptyset \sststile{q}{q} \irl{nil} : L^p(A)
}{
}(\text{L:Nil})

\inferr{
  \Sigma; x_h : A, x_t : L^p(A) \sststile{q}{q+p+1} \consexcst{x_h}{x_t} : L^p(A)
}{
}(\text{L:Cons})

\inferr{
  \Sigma; \Gamma, x : L^p(A) \sststile{q'}{q} \listcaseexcst{x}{e_1}{x_h}{x_t}{e_2} : B
}{
  \Sigma; \Gamma \sststile{q'}{q} e_1 : B \\
  \Sigma; \Gamma, x_h : A, x_t : L^p(A) \sststile{q'}{q + p + 1} e_2 : B
}(\text{L:MatL})

\inferr{
  \Sigma; \Gamma, x : A \sststile{q'}{q} \sharecpcst{x}{x_1}{x_2}{e} : B
}{
  A \;\curlyvee \;A_1, A_2\\
  \Sigma; \Gamma, x_1 : A_1, x_2 : A_2 \sststile{q'}{q} e : B
}(\text{L:Share})

\inferr{
  \Sigma; \Gamma_1, \Gamma_2 \sststile{q'}{q} \irl{let}(e_1; x : \tau.e_2) : B
}{
  \Sigma; \Gamma_1 \sststile{p}{q} e_1 : A \\
  \Sigma; \Gamma_2, x : A \sststile{q'}{p} e_2 : B
}(\text{L:Let})
\end{mathpar}
  
  \caption{Type Rules of Classic AARA~\cite{Jost03}}
  \label{fig:typeRules}
\end{figure}

\yue{remove the example}
Recall that we gave the bound $2m+3$ to dfs in the introduction.
Formally, this means we can give the following type derivation to dfs:
\[
	\Sigma; \texttt{t} : \texttt{btree}^2(\irl{nat}), \texttt{x} : \irl{nat} 
		\sststile{0}{3} \texttt{dfs t x} : \irl{nat\_ option}
\]

Where $\Sigma = [\texttt{dfs} : 
	\prodtycst{\texttt{btree}^2(\irl{nat})}{\irl{nat}} \xrightarrow{3/0} \irl{nat\_ option}]$.\\

{\bf New Rules}
%
The new type system for programs with garbage collection replaces the rules L:MatL and L:Share. The observation is that if we ensure 
that locations are used linearly, we can use destructive pattern matching to model 
local garbage collection by returning the potential associated with the constructor location
(notice the extra $+1$ in the second premise):
%
{\small \[
\inferr{
  \Sigma; \Gamma, x : L^p(A) \sststile{q'}{q} \listcaseexcst{x}{e_1}{x_h}{x_t}{e_2} : B
}{
  \Sigma; \Gamma \sststile{q'}{q} e_1 : B \\
  \Sigma; \Gamma, x_h : A, x_t : L^p(A) \sststile{q'}{q + p + 1} e_2 : B
}(\text{L:MatLD})
\]}

This is validated by the fact (Lemma \ref{itm:na}) that in the auxiliary linear cost semantics 
\copySem{} once a cons-cell is matched on, 
there can be no live references from the root set to it, and thus 
we are justified in restituting the potential to type the subexpression $e_2$. \yue{forward ref to copy sem}

However, the rule L:MatLD is not sound for programs with aliasing of data. We address this issue by 
replacing the rule L:Share with the rule L:ShareCopy:
%
{\small \[
\inferr{
  \Sigma; \Gamma, x : A \sststile{q'}{q} \sharecpcst{x}{x_1}{x_2}{e} : B
}{
  A \;\curlyvee^1 \;A_1, A_2\\
  \Sigma; \Gamma, x_1 : A_1, x_2 : A_2 \sststile{q'}{q} e : B
}(\text{L:ShareCopy})
\]}

To share a variabe of type $A$, we need to split the potential between two new annotated types 
$A_1$ and $A_2$ as usual. In addition, we have to pay an ``overhead'' of 1 for every cons node 
in any structure in $\llbracket A \rrbracket$. The idea is that we treat data as if it is
actually copied. \yue{say something about soundness}

\yue{replace with append}
Now, we can give the now \emph{constant} space overhead bound to dfs:
\[
	\Sigma; \texttt{t} : \texttt{btree}^0(\irl{nat}), \texttt{x} : \irl{nat} 
		\sststile{0}{2} \texttt{dfs t x} : \irl{nat\_ option}
\]

Where $\Sigma = [\texttt{dfs} : 
	\prodtycst{\texttt{btree}^0(\irl{nat})}{\irl{nat}} \xrightarrow{2/0} \irl{nat\_ option}]$.\\

{\bf Cost Metrics}
In previous versions of AARA~\cite{Jost10,HoffmannAH10}, the typing judgment and cost semantics
are parametrized by a \emph{cost metric} 
$m : \ms{res\_const \to \mathbb{Q}}$, which assigns a constant cost to 
each step in the semantics.
Since the cost for all program construct is zero save for the cons
data constructor, we elide the cost metric altogether. Although we defined the constructor to cost
1 heap location (as shown in L:Cons and L:MatL), it can be any constant as long as the introduction
and elimination rules agree on that constant. Thus we can extend the type system to accurately track
closure sizes and constructor which vary in size depending on the argument (more in 
Section~\ref{sect:conclusion}).

{\bf Type Inference} One of the benefits of AARA is efficient type
inference using off-the-shelve LP solvers~\cite{Jost03}, even for
non-linear potential functions~\cite{HoffmannAH10,HoffmannW15}. The
new rules do not complicate inference and previous techniques still
apply. In a nutshell, inference is performed in three steps: First,
perform a standard Hindley-Milner type inference for the base
types. Then, annotate the type derivation with (yet unknown) variables
for the potential annotations and collect linear constraints that are
derived from the type rules. Finally, solve the constraints with an LP
solver and minimize the potential annotations of the inputs. Details
can be found in previous work~\cite{Jost03,HoffmannW15}.


%------------------------------------------------------------------------------

\section{Soundness of $\fogc$}

We seek to prove the following theorem.

\begin{theorem}[Soundness]
\label{itm:soundness} Let $H \vDash V {:} \Gamma$, $\;\; \Sigma; \Gamma \sststile{q'}{q} e : B$,
and $V,H \vdash e \Downarrow v, H'$.
Then for all $F,R \subseteq \ms{Loc}$:
If $|F| \ge \Phi_{V,H}(\Gamma) + q$,
then there exists a value $w$, and a freelist $F'$ such that
$$
\begin{array}{ccc}
	V,H,R,F \vdash^{\gcSem} e \Downarrow w, Y', F'  & \text{ and } & \veq{H'}{Y'}{v}{w} \; .
\end{array}
$$
\end{theorem}

Here, $V,H \vdash e \Downarrow v, H'$ is a standard big-step evaluation judgment
derived from \gcSem{} and $\veq{H'}{Y'}{v}{w}$ is value equivalence. The theorem states that,
given a terminating expression
and a freelist that is sufficiently large (as predicated by the type derivation), 
a run with \gcSem will normalize to an equivalent value.

To facilitate the proof, we define an intermediate semantics
\copySem{} which is semantically linear. The proof has two stages:
First, we show \copySem{} over-approximates \gcSem, meaning that any
computation that succeeds with \gcSem{} will succeed with an
equally-sized or smaller freelist with \gcSem{}. Then we show $\fogc$
is sound with respect to \copySem{}, and thus by the previous step sound with respect to
\gcSem{}.

\textbf{Linear Garbage Collection Cost Semantics}
\label{sect:copy}
To establish the soundness of the type system, we need an 
intermediary semantics \copySem{}, which is \emph{semantically linear}.  
As mentioned in Section~\ref{sect:fop}, this means that locations are linear, that is, no location can be 
used twice in a program. Variable sharing is achieved via \emph{copying}: 
the shared value is created by allocating a fresh set of locations from the freelist and copying the 
locations of the original value one by one. This is also sometimes referred to as deep copying.
Let $copy(H,L,v,H',v')$ be a 5-place relation on 
$\ms{Heap} \times \mathcal{P}(\ms{Loc}) \times \ms{Val} \times \ms{Heap} \times \ms{Val}$. 
Similar to reachability, we write this as 
$H',v = copy(H,L,v)$ to signify the intended mode for this predicate: $(+,+,+,-,-)$.
{ \small \begin{mathpar}
	\inferr{
		H,v = copy(H,L,v)	
	}{
		v \in \{n,\irl{T},\irl{F},\irl{Null}\}
	}

	\inferr{
		H'\{l' \mapsto v\},l' = copy(H,L,l) 
	}{
		l' \in L\\
		H',v = copy(H,L \setminus \{l'\},H(l)) 
	}

\inferr{
	H_2,\pairexcst{v_1'}{v_2'} = copy(H,L,\pairexcst{v_1}{v_2})
}{
	L_1 \sqcup L_2 \subseteq L\\
	|L_1| = |dom(reach_H(v_1)|\\
	|L_2| = |dom(reach_H(v_2)|\\
	H_1,v_1' = copy(H,L_1,v_1)\\
	H_2,v_2' = copy(H_1,L_2,v_2)\\
}
\end{mathpar}}

Primitives require no cells to copy; a location value is copied recursively; 
a pair of values is copied sequentially, and the total number of cells required 
is the size of the reachable set of the value.  
Now, consider \gcSem{} with the share rule F:Share replaced with the following rule.
{\small \[
\inferrule{
	V(x) = v\\
  L \subseteq F\\
  |L| = |dom(reach_H(v'))|\\
  H',v'' = copy(H,L,v')\\
	V_2 = (V[x_1 \mapsto v',x_2 \mapsto v'']) \restriction_{FV(e)}\\
	F' =	F \setminus L\\
	g = \{l \in H \mid l \notin F' \cup R \cup locs_{V_2,H}(e)\}\\
 	V_2,H',R,F' \sqcup g \; \vdash e \Downarrow v,H'',F'
}{
  V,H,R,F \; \vdash \sharecpcst{x}{x_1}{x_2}{e} \Downarrow v,H'',F'
}(\text{E:Share})
\]}

To share a variable, we first copy the shared value. The number of cells required is equal to the
size of the reachable set from the value. This copying sharing semantics is what justifies the 
analysis to use restitute the potential when matching on a cons node, 
since even if the node was shared, we had to pay for the cost by copying the node when sharing the 
original value. Next, we restrict the stack to the appropriate variables. 
Lastly, any locations not reachable from the current subexpression $e$ is collected. This is 
for the case when a variable is shared but not used later.  

Intuitively, we expect that any terminating compuation
with \copySem{} has a corresponding run with \gcSem{} that can be instantiated with 
an equally-sized or smaller freelist. Although this seems quite straightforward to prove, a complete
characterization of the relationship of between the space allocations of two runs with each 
semantics is necessary. To motivate this, consider the following proof attempt: 

\begin{attempt}
	Let $\mathcal{C_2} = (V,H,R,F)$ be a configuration and $(\mathcal{C_2}, e)$ 
	be a linear computation. Given that 
	$\mathcal{C}_2 \vdash^{\mathsf{copy}} e \Downarrow v,H',F'$, and $H' \vDash v \mapsto a : A$, 
	for all configurations $\mathcal{C}_1 = (W,Y,R,M)$ such that $W,Y \sim V,H$ and $|M| = |F|$,
there is exists a triple
$(w,Y',M') \in \ms{Val} \times \ms{Heap} \times \ms{Loc}$ such that
	\begin{center}
			$\mathcal{C}_1 \vdash^{\mathsf{free}} e \Downarrow w,Y',M'$
		\hspace{3em} and \hspace{3em}	 $\veq{H'}{Y'}{v}{w}$
		\hspace{3em} and \hspace{3em}	 $|M'| \ge |F'|$ .
	\end{center}
\end{attempt}

We proceed with induction on the derivation of the judgment in \copySem. 
Almost every case goes through, save for E:Let. 
First, we get $W_1,Y \sim V_1,H$ and We have the following from induction on the first premise:
%
\begin{center}
	 $W_1,Y,R',M \vdash^{\mathsf{free}} e \Downarrow w_1,Y_1,M_1$
   \hspace{3em} and \hspace{3em}	 $\veq{H_1}{Y_1}{v_1}{w_1}$
   \hspace{3em} and \hspace{3em}	 $|M_1| \ge |F_1|$
\end{center}
%
To instantiate the induction hypothesis on the second premise, we need to show that, among 
other things, $|M_1 \cup j| \ge |F_1 \cup g|$, where $j$ is the set of collected locations in 
the \gcSem{} judgment. We cannot show this precisely because $g$ might contain more cells 
then $j$ due to the linearity of \copySem{}, thus preventing a piecewise comparison. 
But of course $|j|$ is always less than $|g|$, since \gcSem{} doesn't copy to share 
values! This shows that there is a mismatch between the induction hypothesis and the relationship
between the sizes of the respective freelists and the garbage sets. We present the following 
criteria which characterizes the required equivalence between two configuration,
called \emph{copy extension}.

\begin{definition}
A configuration $\mathcal{C}_2 = (V_2,H_2,R_2,F_2)$ is a \emph{copy extension} of another configuration
$\mathcal{C}_1 = (V_1,H_1,R_1,F_1)$ iff
\begin{enumerate}
\item $V_1,H_1 \sim V_2,H_2$
\item There is a proper partition $\gamma : dom(H_1) \setminus F_1 \to \mathcal{P}(dom(H_2) \setminus F_2)$ 
such that for all $l \in dom(\gamma)$, $|\gamma(l)| = reach_{H_1}(V_1)(l) + R_1(l)$
\item For all $l \in dom(\gamma)$, $x \in dom(V_1)$, valid sequence of directions $P$ w.r.t $V_1(x)$,
	$|reach_{H_2}(V_2(x;P)) \cap \gamma(l)| = reach_{H_1}(V_1(x;P))(l)$.
\item $R_1 \subseteq dom(H_1) \setminus F_1$ and 
	for all $l \in R_1$, $|\gamma(l) \cap R_2| = R_1(l)$
\item $|F_1| = |F_2| + |\oh{\gamma}|$, where 
	$\oh{\gamma} = \bigcup_{P \in ec(\gamma)} P \setminus (rep(P))$
\end{enumerate}
Write this as $\mathcal{C}_1 \preceq \mathcal{C}_2$.
\end{definition} 
The intention is that $\mathcal{C}_2$ is a configuration for initiating an evaluation using \copySem
, and $\mathcal{C}_1$ a configuration for \gcSem. 
The first condition is the straightforward context equivalence.
The second condition requires the existence of 
a mapping $\gamma$ that tells us given a location in $H_1$, which locations in $H_2$ 
are shared instances.

For example, consider the expression $\sharecst{x}{x_1}{x_2}{e}$ and
assume the stack is $[\texttt{x} \mapsto 1]$, and the heap equals 
$[1 \mapsto \pairexcst{0}{\irl{Null}}]$, i.e. \texttt{x} is the list \texttt{[0]}.
In an evaluation with \gcSem{}, the stack becomes 
$[\texttt{x1} \mapsto 1,\texttt{x2} \mapsto 1]$, and the heap does not change. With 
\copySem, we allocate a new location in the heap:
$[1 \mapsto \pairexcst{0}{\irl{Null}},2 \mapsto \pairexcst{0}{\irl{Null}}]$, and the 
stack changes accordingly: $[\texttt{x1} \mapsto 1,\texttt{x2} \mapsto 2]$.
Now $\gamma$ would map 1 to $\{1,2\}$, since both are shared instances of the former.

Thus, each $\gamma(l)$ is mapped to a disjoint subset in $H_2$, and each location in $H_2$ 
would have a representative in $H_1$. Furthermore, we noticed it is crucial to include the 
fact that the size of $\gamma(l)$ must be the sum of the number of references from the stack and 
the continuation set. 

While $\gamma$ gives us a relation between the two respective heaps, we still need to know 
exactly how variables on the stack factor in this relationship. Let $l \in H_1$. 
Specifically, we need to know that the number of references to $l$ from every \emph{sub}value
in $V_1$ is equal to the size of the corresponding part of the class $\gamma(l)$.  
First, we need to access 
subvalues of a value using directions: 

\begin{definition}
	Let \ms{dir} be the set \{\ms{L},\ms{R},\ms{N}\}, denoting left, right, and next 
	respectively. We can index values via directions:
        $$
	\begin{array}{lclclcl}
		get_H(Just(\pairexcst{v_1}{v_2},\ms{L})) &=& Just(v_1) & \hspace{4em} &
		get_H(Just(\pairexcst{v_1}{v_2},\ms{R})) &=& Just(v_2)\\
		get_H(Just(\pairexcst{v_1}{v_2}),_) &=& None &&
		get_H(Just(l),\ms{N}) &=& Just(H(l)) \\
		get_H(Just(l), \_) &=& None &&
		get_H(r,\_) &=& r
	\end{array}
        $$
	Let $P$ be a sequence of directions. Extend $get$ to sequence of directions:
	\begin{align*}
		find_H(v,D::P) &= find_H(get_H(v,D),P)\\
		find_H(v,[]) &= v
	\end{align*}
	Call $P$ valid w.r.t a value $v$ if $find_H(v,P) = Just (v')$ for some $v'$.
	Write $V_H(x;P)$ for $fromJust(find_H(V(x),P))$ given a valid sequence $P$ w.r.t $V(x)$,
	and $reach_H(V(x;P))$ for $reach_H(V_H(x;P))$.
	Given a map $m : X \to \mathcal{S}(\ms{dir})$ from varibles to valid sequences of directions, 
	Define $reachPath_{V,H}(X,m) = \biguplus_{x \in X} reach_H(V(x;m(x)))$.
\end{definition}

With this, the third condition gives us a more fined grained restriction: for any subvalue in $V_1$,
the number of references from it to $l$ is equal to the size of 
the intersection of the reachable set of the corresponding subvalue in $V_2$
with the appropriate class $\gamma(l)$ .

The next condition simply states that the continuation sets respect $\gamma$. Lastly, 
we have have that $F_1$ is greater $F_2$, with the overhead being exactly the sum 
$\sum_{l \in \gamma} |\gamma(l)| - 1$. 

\begin{definition} A configuration $(V,H,R,F)$ is well-formed if 
	$dom(H) \subseteq reach_H(V) \cup R \cup F$ and $reach_H(V) \subseteq dom(H)\setminus F$.
\end{definition}

Now we can formulate the key lemma:

\begin{lemma}
	Let $(\mathcal{C}_2,e)$ be a linear computation. Given that 
	$\mathcal{C}_2 \vdash^{\mathsf{copy}} e \Downarrow v,H',F'$, and $H' \vDash v \mapsto a : A$, 
	for all well-formed configurations $\mathcal{C}_1$ such that $\mathcal{C}_1 \preceq \mathcal{C}_2$,
there is exists a triple
$(w,Y',M') \in \ms{Val} \times \ms{Heap} \times \ms{Loc}$ and 
	$\gamma' : dom(Y') \setminus M' \to \mathcal{P}(dom(H') \setminus F')$ s.t.
	\begin{enumerate}
			\item $\mathcal{C}_1 \vdash^{\mathsf{free}} e \Downarrow w,Y',M'$
			\item $\veq{H'}{Y'}{v}{w}$
			\item $\gamma'$ is a proper partition, such that for all $l \in dom(\gamma')$, 
				$|\gamma'(l)| = |reach_{Y_1}(w_1)(l)| + S(l)$
			\item For all $P$, $|reach_{H'}(find_{H'}(v;P)) \cap \gamma'(l)| = 
				reach_{Y'}(find_{Y'}(w;P))(l)$
			\item $\gamma'(l) \cap R = \gamma(l) \cap R$
			\item $|M'| = |F'| + |\oh{\gamma'}|$
	\end{enumerate}
\end{lemma}

The third condition deserves some explanation. The size of $\gamma(l)$ should equal the total number 
of ways $l$ could be reached from the root set in the \gcSem evaluation. This includes 
$reach_{Y_1}(w_1)(l)$ and $S(l)$, but also any paths to $l$ had been collected during the run 
(this accounts for unused variables that referenced $l$).

\yue{move the following to the appendix}
For a configuration $\mathcal{C} = (V,H,R,F)$, denote the current garbage w.r.t a set of root variables 
$X \subseteq dom(V)$ 
as $clean(\mathcal{C},X) = \{l \in H \mid l \notin F \cup R \cup reach_H(X)\}$. Some auxiliary lemmas: 

\begin{lemma}\label{itm:aux}
Let $V_2,H_2,R_2,F_2 \vdash^{\mathsf{copy}} e \Downarrow v,H',F'$, and 
$V_1,H_1,R_1,F_1 \preceq V_2,H_2,R_2,F_2$ because $(-,\gamma,\eta,-,-)$. Then the following hold:
\begin{enumerate}
\item for all $l \in dom(H_1) \setminus F_1$, 
$X \subseteq dom(V)$, $\gamma(l) \subseteq clean(\mathcal{C}_2,X)$ implies that 
$l \in clean(\mathcal{C}_1,X)$.
\end{enumerate}
\end{lemma}

Thus, we have shown that we can execute a computation using the 
\gcSem if the computation suceeded in a run with \copySem, and that indeed 
\copySem is an over approximation of \gcSem.

\textbf{Soundness of \copySem}
\label{sect:soundcopy}
To state the soundness theorem,
we introduce an standard big step semantics
that does not use freelists or accounts for garbage collection. We use
it to characterize expressions that normalize to values when initialized with a sufficient 
freelist.  This technique has also be  employed in earlier work on AARA~\cite{Hofmann:2003:SPH:604131.604148}.
This operational semantics defines 
judgments of the following form, essentially a simplified version of the full cost semantics:
\fbox{$V,H \vdash e \Downarrow v, H'$}.

This can be read as: under stack $V$, heap $H$ the expression $e$ evaluates to $v$, 
and engenders a new heap $H'$. The rules are entirely standard and are omitted here.
In $\ms{oper}$, the ``freelist'' is the whole ambient set of locations $\ms{Loc}$, 
thus we never run out of locations during evaluation. This introduces a problem when comparing 
evaluation results between a run with \copySem{} and $\ms{oper}$, as the return values 
might not be syntatically equal. Consider the following expression
\texttt{let \_ = [4] in [5]}
%
Assuming locations are natural numbers, and we run \copySem{} with the freelist $\{1\}$. 
First, 1 is allocated and mapped to $\texttt{[4]}$. 
Then, since the first subexpression $\texttt{[4]}$ is not used afterwards, we collect 1, and reuse it
and map again to $\texttt{[5]}$. Thus the return value is 1.  In a run with $\ms{oper}$, 
we also first map 1 to $\texttt{[4]}$, but then 
allocate a new location, say 2, and map it to $\texttt{[5]}$, and the return value is 2. Due to the 
difference in allocation strategies and the fact that both are nondeterministic, we need a more 
robust notion of equality for values. Luckily, the structures from the denotational semantics 
does the job. In both runs, the return value maps to the semantic value $\texttt{[5]}$.
Thus semantical equality serves as the basis for context equivalence. 
Here we define it for contexts, which consisting of only the stack and heap. 
Later, we extend it the the full configuration. First, define value equivalence as
a shorthand for semantic equality: \yue{the previous paragraph can be shortened if we need space}

\begin{definition}[Value Equivalence]
Two values $v_1,v_2$ are equivalent (with the presupposition that they are well-formed w.r.t heaps $H_1,H_2$),
iff $H_1 \vDash v_1 \mapsto a : A$ and $H_2 \vDash v_2 \mapsto a : A$. 
Write value equivalence as $\veq{H_1}{H_2}{v_1}{v_2}$.
\end{definition}

\begin{definition}[Context Equivalence]
Two contexts $(V_1,H_1), (V_2,H_2)$ are equivalent
(with the presupposition that both are well-formed contexts) iff $dom(V_1) = dom(V_2)$ and 
for all $x \in dom(V_1)$, $\veq{H_1}{H_2}{V_1(x)}{V_2(x)}$. Write context equivalence as 
$\ctxeq{V_2,H_2}{V_2,H_2}$
\end{definition}

Stated simply, two contexts are equivalent when they have the same domain and equal variables bind 
equal semantic values. 
%
With this, we are ready to state the soundness theorem.

\begin{theorem}[Soundness]
\label{itm:soundness} let $H \vDash V : \Gamma$, $\Sigma; \Gamma \sststile{q'}{q} e : B$,
$V,H \; \vdash e \Downarrow v, H'$, and $H' \vDash v \mapsto a : A$.
Then $\forall C \in \mathbb{Q}^{+}$ and $\forall F,R \subseteq \ms{Loc}$,
if the following holds:
\begin{enumerate} 
\item $\wfc{V}{H}{R}{F}{e}$
\item $|F| \ge \Phi_{V,H}(\Gamma) + q + C$ 
\end{enumerate}
then there exists a context $(W,Y)$, a value $w$, and a freelist $F'$ s.t.
\begin{enumerate}
	\item $\ctxeq{W,Y}{V,H}$
  \item $W,Y,R,F \vdash e \Downarrow w, Y', F'$
	\item $\veq{H'}{Y'}{v}{w}$
  \item $|F'| \ge \Phi_{H'}(v:B) + q' + C$
\end{enumerate}
\end{theorem}

In other words, given a terminating expression (verified by succeeding with the run using \ms{oper})
and given a freelist that is sufficiently large (as predicated by the type derivation), 
a run with \copySem will normalize to an equivalent value, and the resulting freelist 
will be sufficiently large (as predicated by the type derivation).




%------------------------------------------------------------------------------


\section{Implementation and Evaluation}
\label{sect:implementation}

{\bf Implementation}
We have implemented the novel cost semantics and the type system in
Resource Aware ML (RaML). The implementation covers full RaML,
including user-defined data types, higher-order functions, and
polynomial potential functions. However, there is no destructive match
for function closures and analyzing the heap-space usage of closures
still amounts to counting allocations only. The main changes that
where necessary have been in the rules for sharing and pattern
matching as described earlier. We also needed to change some
elaboration passes that were not cost preserving anymore with
the GC cost model.

The garbage collection cost semantics is implemented as an alternative evaluation module inside
RaML. As mentioned before, RaML leverages the syntax of OCaml programs.
First, we take the OCaml type checked abstract syntax tree and perform a series of transformations. 
The evaluation modules operates on the resulting RaML syntax tree. 
In the gc evaluation module, \texttt{evaluate} has the following signature:
{\small%
\begin{verbatim}
 evaluate : ('a, unit) Expressions.expression -> int -> (('a value * 'a heap * Int.Set.t) option) 
\end{verbatim}
}
Here, the second argument \texttt{int} specifies the size of the initial freelist.
The result is a triple of the return value, heap, and freelist, or \texttt{None} 
in case the freelist was not sufficient for the evaluation.
Whereas the normal evaluation boxes every value (everything evaluates to a location), 
the gc module follows the cost semantics and only boxes data constructors. The rationale is
that the size for other values can be computed statically and stack allocated. One difference
between the cost semantics and its implementation is that while in the language presented here
list is the only data type, our implementation supports user defined data types. The extension
is straightforward except the treatment of the nil constructor, or generally ``empty'' constructors
that has arity zero. For simplicity of presentation, we evaluate all nil constructors to
the same null value in the cost semantics. This is natural for lists because all nil constructors 
are the same, and every list has at most one nil node. However, for custom data types that have 
more than one kind of empty constructor, it is not possible to map every constructor to the same 
null value. Thus, the implementation treats all constructors uniformly, so each nil constructor
also cost one heap location. 

As mentioned before, all functions used in a program are declared in a global mutually 
recursive block, and we do not account for the constant space overhead for this block in 
the cost semantics.  In order to implement this global function block, we allow closure creation
during program evaluation. However, we allocate all closures from a separate freelist into 
a separate heap.  This ensures that data constructors are allocated from the correct freelist 
and no space overhead is created by allocating closures for function declarations.


\label{sect:evaluation}
\begin{wraptable}{r}{0.5\textwidth}
\small
	\vspace{-20pt}
		\begin{center}
	\begin{tabular}{ll}
		\hline
		\textit{\textbf{function}} & type \\ \hline
		quicksort & {[}'a -\textgreater 'a -\textgreater bool; 'a list{]} -\textgreater 'a list \\
		mergesort & {[}{[}'a; 'a{]} -\textgreater bool; 'a list{]} -\textgreater 'a list \\
		ocamlsort & {[}{[}'a; 'a{]} -\textgreater bool; 'a list{]} -\textgreater 'a list \\
		selection sort & int list -\textgreater int list \\
		eratosthenes & int list -\textgreater int list \\
		dfs & {[}btree; int{]} -\textgreater btree option \\
		bfs & {[}btree; int{]} -\textgreater btree option \\
		transpose & 'a list list -\textgreater 'a list list \\
		map\_it & {[}'a -\textgreater 'b; 'a list list{]} -\textgreater 'b list list * 'b list list\\
		pairs & 'a list -\textgreater ('a * 'a) list \\ \hline
	\end{tabular}
			\end{center}
				\vspace{-10pt}
			\caption{Signature of Test Functions}
		\vspace{-10pt}
\label{table:sig}
\end{wraptable}

\textbf{Evaluation}
We evaluated our new analysis on a number of functions. Table~\ref{table:sig} contains a representative compilation.
It shows the type signature for each function. Table~\ref{table:bounds} presents the test 
data that
showcase the difference between the heap metric, the old analysis which only counts 
heap allocations, and the gc metric, which includes deallocations and copying cost for sharing.
For each metric, we show the heap space bound computed by RaML, 
the number of constraints generated, and the time elapsed during analysis. The last column gives
the expression for the exact heap high watermark derived by hand and verified by running the 
cost semantics.

Except for bfs and dfs, all functions in the table take a \emph{principal} argument of type list. 
The variables in the table refer to this argument (for example, the type of the 
principal argument of 
quicksort is 'a list). In general, M refers to the number of cons constructors of the principal 
argument (or the number of \emph{outer} cons nodes in case of nested lists); L refers to the
maximum number of cons nodes of the inner lists.

For the sorting functions aside from mergesort, the new analysis using the gc metric
derived asymptotically better bounds when compared to the heap metric. Furthermore,
all bounds are \emph{exact} with respect to the cost semantics. In regards to mergesort, 
the analysis was not able to derive a tight bound due to the limitations of AARA in deriving 
logarithmic bounds. A particularly nice result is that we can deduce for quicksort, 
the space usage is exactly 0, which justifies its use as a zero space-overhead sorting algorithm.

Next, we have have the graph search algorithms operating on a binary tree. Again, the gc metric
was able to derive exact space overheads, while the heap metric derived linear bounds for both.
%
For transpose, the gc metric derived an asymptotically better bound, but was not able to derive 
the exact overhead. We implement matrices as lists-of-lists in row-major order. 
The transpose function is implemented tail-recursively, with the accumulator starting as the 
empty list. When ``flipping'' the first row $r$ of the input and appending this to the accumulator, 
we need to create $|r|$ many new nil and cons constructors to store the row as a column. While this
overhead only occurs once, RaML is unable to infer this from the source code, and thus the cost
is repeated over the entire input matrix, resulting in the linear bound (w.r.t the size of the 
matrix). 

The last two functions demonstrate how the gc metric performs when there is variable sharing.
map\_it maps the input function across each list in the principal argument twice, returning a
tuple of nested lists. The gc metric dictates that every outer data constructor in the 
principal argument needs to be copied, and thus gives the linear bound M + 1. In this case,
the bound is exact. The pairs functions takes a list and outputs a all pairs of the input list 
which are ordered ascending in input position. For example, 
pairs [1;2;3;4] = [(1,2);(1,3);(1,4);(2,3);(2.4);(3,4)]. For pairs, the gc metric derived a bound
that is asymptotically the same as the heap metric, but with better constants. An exact bound 
could not be derived because the deallocation potential from the pattern match in the 
definition of pairs is wasted because the matched body could already be typed with zero cost. 
However, this deallocation is used as usual in the cost semantics. Thus the slack in the bound 
totals to the size of the input. % This example shows a weakness in the new gc metric and analysis; 
% we discuss possible solutions and different approaches in the next sections. 




% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
\begin{table}[]
	\begin{adjustbox}{width=1.1\textwidth,center=\textwidth}
  \begin{tabular}{@{}llllllllll@{}}
		\toprule
		 & \multicolumn{4}{l}{heap metric} & \multicolumn{4}{l}{gc metric} &  \\ \midrule
		 \textit{\textbf{function}} & computed bound & asymptotic & constraints & time & computed bound & asymptotic & constraints & time & optimal \\
		 quicksort & 1.00 + 3.50*M + 1.50*M\textasciicircum{}2 & O(M\textasciicircum{}2) & 8515 & 0.52 & 0 & O(1) & 8519 & 0.48 & 0 \\
		 mergesort & 1.00 - 4.67*M + 6.33*M\textasciicircum{}2 & O(M\textasciicircum{}2) & 9572 & 0.64 & -0.50*M + 0.50*M\textasciicircum{}2 & O(M\textasciicircum{}2) & 9578 & 0.58 & $\lfloor \log(M) \rfloor$ \\
		 ocamlsort & 7.50 + 5.50*M + 1.00*M\textasciicircum{}2 & O(M\textasciicircum{}2) & 8565 & 0.51 & 1.00 + 1.00*M & O(M) & 8573 & 0.50 & M+1 \\
		 selection sort & 2.00 + 3.00*M + 1.00*M\textasciicircum{}2 & O(M\textasciicircum{}2) & 639 & 0.06 & 0 & O(1) & 642 & 0.05 & 0 \\
		 eratosthenes & 1.00 + 1.50*M + 0.50*M\textasciicircum{}2 & O(M\textasciicircum{}2) & 515 & 0.06 & 0 & O(1) & 517 & 0.04 & 0 \\
		 dfs & 3.00 + 2.00*M & O(M) & 5481 & 0.90 & 2 & O(1) & 5483 & 0.36 & 2 \\
		 bfs & 5.00 + 10.00*M & O(M) & 24737 & 4.15 & 4 & O(1) & 24742 & 1.62 & 4 \\
		 transpose & 1.00 + 3.50*L*M + 0.50*L*M\textasciicircum{}2 & O(L*M\textasciicircum{}2) & 10680 & 0.50 & 1.00 + 2.00*L*M & O(L*M) & 10684 & 0.50 & max(0,2*L-1) \\
		 map\_it & 2.00 + 2.00*L*M + 4.00*M & O(L*M) & 30699 & 1.58 & 1.00*M + 1.00 & O(M+N) & 30703 & 1.57 & M + 1 \\
		 pairs & 1.00 + 1.00*M\textasciicircum{}2 & O(M\textasciicircum{}2) & 10214 & 0.60 & 0.50*M + 0.50*M\textasciicircum{}2 & O(M\textasciicircum{}2+M*N) & 10217 & 0.64 & 0.5*M\textasciicircum{}2-1.5*M+2 \\ \midrule
	\end{tabular}
	\end{adjustbox}
\caption{Automatic Bound Analysis with RaML \yue{remove asymptotic columns; the bounds could be typeset nicer in math mode and without *'s and 0's}}
\label{table:bounds}
\end{table}

\section{Conclusion and Future Work}
\label{sect:conclusion}

\jan{discuss function closures}

In this article, we introduced a novel operational cost semantics that models a perfect tracing 
garbage collector and an extension to AARA that is sound with respect to the new semantics.
We implemented the new semantics and analysis as modules in RaML and found through 
experimental testing that the extended AARA was able to derive asymptotically better bounds 
for several commonly used functions and programming patterns; often, the bounds are optimal 
with respect to the cost semantics.

One direction for future work is using the \emph{cost free} metric $\ms{cf}$ to model global garbage 
collection. In $\ms{cf}$, all resource constants, including constructor nodes, are set to 0.
A cost-free typing judgment then captures how an expression 
manipulates the structures in the context into the
the structure induced by its type. Using this fact, we are inspired to write the following rule:

\[
\inferr{
  \Sigma; \Gamma_1, \Gamma_2 \sststile{q'}{q} \irl{let}(e_1; x : \tau.e_2) : B
}{
  \Sigma; \Gamma_1 \sststile{p}{q} e_1 : A \\
  \Sigma; \Gamma_1 \sststile{}{\ms{cf}} e_1 : A' \\
  \Sigma; \Gamma_2, x : (A' - 1) \sststile{q'}{p} e_2 : B
}(\text{L:Let})
\]

Which states that to type a composition, we need to be able to type the first expression. 
Next, we note that instead of paying for every allocation in $e_1$, 
we only need to pay for the unit potenital for each constructor in the result $A$.
Thus we also type $e_1$ with the cost-free metric, so the result type $A'$
contains the same amount of potential as the context $\Gamma_1$, and pay for the 
constructors by removing unit potential from every node in $A$, and type $e_2$ with 
the resulting type $A'-1$. This cost-free composition rule would bring the type system closer 
to modeling the composition in the garbage collection cost semantics.

In \cite{Hoffmann:2015:ASC:2769448.2769449}, the authors have successfully employed this 
cost-free metric to analyze parallel programs. Here, the difficulty is showing
the simultaneous soundness of both destructive pattern matching and the cost-free composition. 
Another complication is the choice between local variable sharing and global context sharing.
We leave the exploration of this area to future work.

\jan{Use analysis for ocaml garbage collector}
\newpage
\label{sect:bib}
\bibliographystyle{plain}
%\bibliographystyle{alpha}
%\bibliographystyle{unsrt}
%\bibliographystyle{abbrv}
\bibliography{easychair,lit}

%------------------------------------------------------------------------------
\appendix

\section{Notation}
\label{sect:notation}
For a finite mapping $f : A \to B$, we write $dom$ for the defined values of $f$. Sometimes we shorten $x \in dom(f)$ to $x \in f$. We write $f[x \mapsto y]$ for the extension of $f$ where $x$ is mapped to $y$, with the constraint that $x \notin dom(f)$. 

Given possibly non-disjoint sets $A,B$, let the disjoint union be $A \oplus B$ defined by 
$\{(\ms{inl},a) \mid a \in A\} \cup \{(\ms{inr},b) \mid b \in B\}$.

Let a multiset be a function $S : A \to \mathbb{N}$, i.e. a map of the multiplicity of each element in the domain.  Write $x \in S$ iff $S(x) \ge 1$. If for all  $s \in S$, $\mu(s) = 1$, then $S$ 
is a property set, and we denote this by $\ms{set}(S)$. Addtionally, $A \uplus B$ denotes 
counting union of sets where $(A \uplus B) (s) = A (s) + B(s)$, similarly, 
$(A \cap B)(s) = \min{A(s),B(s)}$. Furthermore, $A \cup B$ denotes the usual union where 
$(A \cup B)(s) = \max{(A(s),B(s))}$.  For the union of disjoint multi-sets $A$ and $B$, 
we write $A \sqcup B$ to emphasize the disjointness.  For a collection of pairwise disjoint 
multi-sets $\mathcal{C}$, i.e. $\forall X,Y \in \mathcal{C}$. $X \cap Y = \emptyset$, we write $\dist{\mathcal{C}}$.

In the rest of the paper, 
we sometimes treat a set $A$ sets as multiset $A : A \to \mathbb{N}$ via 
$x \mapsto \begin{cases} 1 &\text{ if } x \in A \\0 &\text{ o.w.}\end{cases}$ when convenient. 
For instance, if an operation defined on multisets is used on sets and multisets, the set 
is thus promoted.

Given a set $A$, let $\mathcal{P}(A)$ be the powerset of $A$. Given a multiset $A$, let 
$\wp(A)$ be the power multiset of $A$, i.e. the set of all submultisets of $A$.

For a partition $f : A \to \mathcal{P}(B)$, we write the set of equivalence classes
as $ec(f) = \{f(x) \mid x \in A\} = f(A)$, i.e. the image of $f$ on its domain $A$.
Furthermore, a partition is \emph{proper} if for any $x \in A$, $f(x) \neq \emptyset$.

Given a proper partition $f : A \to \mathcal{P}(B)$, for every $a \in A$, 
we can choose an arbitrary 
$b \in f(a)$ to be the representative for that part; call this $rep(a)$.

\section{Linearity of Copy Semantics}

In the soundness proof of $\fogc$, we used an important lemma: that \copySem is 
semantically linear, i.e. locations are used linearly. 
To see why, consider the second premise in the rule L:MatL. In addition to the 
$p$ units of potential justified by the definition of linear potential, we get 1 unit 
from deallocating the cons cell itself. This is only sound if in the corresponding rule in 
\copySem a location was actually collected. Consider the evaluation in question:

\[
\infern{
  V(x) =  l\\
  H(l) = \pairexcst{v_h}{v_t} \\
	V'' = (V[x_h \mapsto v_h, x_t \mapsto v_t])\restriction_{FV(e_2)}\\
  g = \{l \in H \mid l \notin F \cup R \cup locs_{V'',H}(e_2)\}\\
  V'',H,R,F \cup g \; \vdash e_2 \Downarrow v, H',F' \\
}{
  V,H,R,F \; \vdash \listcaseexcst{x}{e_1}{x_h}{x_t}{e_2} \Downarrow v,H',F'
}
\]

If all the variables in $V$ was mapped to values with disjoint reachable sets, 
then we see that $l$ is only in the reachable set of $x$ (assuming that well-typed expressions
don't have duplicate occurences of variables, i.e. $x \notin FV(e_1) \cup FV(e_2)$. 
Then it follows that $l \in g$ given that locations in $V$, $R$, and $F$ are also all disjoint, 
and this is what we needed to justify the rule L:MatL.
Thus we have to show that \copySem preserves the linearity invariant: given a \emph{linear} 
computation, the evaluation result is also linear. 

First, we characterize semantically linear contexts: 

\begin{definition}(Linear context)
Given a context $(V,H)$, let
$x,y \in dom(V)$, $x \ne y$, and $r_x = reach_H(V(x))$, $r_y = reach_H(V(y))$.
	It is \emph{linear} given that:
\begin{enumerate}
\item $\ms{set}(r_x), \ms{set}(r_y)$
\item $r_x \cap r_y = \emptyset$
\end{enumerate}
Denote this by $\na{V,H}$.
\end{definition}

Whenever $\na{V,H}$ holds, visually, one can think of the 
stack as a collection of disjoint, directed trees with locations as nodes; 
consequently, there is at 
most one path from a variable on the stack $V$ to any location in $H$. Now we can 
formalize our intuition for linear computations: 

\begin{definition}[Linear computation]
Given a configuration $\mathcal{C} = (V,H,R,F)$ and an expression $e$, 
we say the 5-tuple $(\mathcal{C},e)$ is a \emph{computation}; it is a \emph{linear computation} 
given the following:
\begin{enumerate}
\item $dom(V) = FV(e)$
\item $\na{V,H}$
\item $\dist{\{R,F,locs_{V,H}(e)\}}$
\end{enumerate} 
And we write $\wfc{V}{H}{R}{F}{e}$ to denote this fact.
\end{definition}

% main lemma
The following lemma one of main results of this paper: given a semantically linear computation 
(one with no sharing between the underlying locations), the resulting value is linear 
(expressed by item 1. and 2. below):
\begin{lemma}[Linearity of \copySem]\label{itm:na}
For all stacks $V$ and heaps $H$, let  $V,H,R,F \; \vdash e \Downarrow v, H', F'$ 
and $\Sigma; \Gamma \vdash e : B$. Then given that $\wfc{V}{H}{R}{F}{e}$, we have the follwoing: 
\begin{enumerate}
\item $\ms{set}(reach_{H'}(v))$
\item $\dist{\{R,F',reach_{H'}(v)\}}$, and
\item $\stable{R,H,H'}$
\end{enumerate}
\end{lemma}

Where $\ms{stable}$ is a predicate on $\mathcal{P}(\ms{Loc}) \times \ms{Heap} \times \ms{Heap}$, defined
below. The premises of this lemma is a subset of the premises of the soundness theorem. 
Thus, we could have
merged the proof of this lemma directly into the soundness proof. However, we think makes the 
presentation clearer; furthermore, the linearity of \copySem is an interesting in itself, 
regardless of the accompanying type system. 

\begin{definition}[Stability]
Given heaps $H,H'$, a set of locations is \emph{stable} if $\forall l \in R$. $H(l) = H'(l)$. Denote this by
$\stable{R,H,H'}$.
\end{definition}

Define $\dagger :  L^p(A) \mapsto L(A)$ as the map that erases resource annotations. 
This gives a simplified jugdment \fbox{$\Sigma^{\dagger}; \Gamma^{\dagger} \vdash e : B^{\dagger}$}
used in proofs where the resource annotations are not necessary.

\begin{lemma}
\label{a} If $\Sigma; \Gamma \sststile{q'}{q} e : B$, then $\Sigma^{\dagger}; \Gamma^{\dagger} \vdash e : B^{\dagger}$.
\end{lemma}

\begin{proof}
Induction on the typing judgement.
\end{proof}

Define $FV^{\star} : \ms{Exp} \to \wp(\ms{Var})$, the multiset of free variables of expressions,
as the usual $FV$ inductively over the structure of $e$. This version of $FV$ reflects 
the multiplicity of variable occurences.

\begin{lemma}\label{itm:linear}
\label{a} If $\Sigma; \Gamma \sststile{q'}{q} e : B$, then $\set{FV^{\star}(e)}$ and $dom(\Gamma) = FV(e)$.
\end{lemma}

\begin{proof}
Induction on the typing judgement.
\end{proof}

\begin{lemma}\label{itm:stable}
Let $H \vDash v \mapsto a : A$. For all sets of locations $R$, if $reach_H(v) \subseteq R$ and $\stable{R,H,H'}$, then $H' \vDash v \mapsto a : A$ and $reach_H(v) = reach_{H'}(v)$.
\end{lemma}

\begin{proof}
Induction on the structure of $H \vDash v \mapsto a : A$.
\end{proof}

\begin{corollary}
Let $H \vDash V : \Gamma$. For all sets of locations $R$, if $\bigcup_{x \in V} reach_H(V(x)) \subseteq R$ and $\stable{R,H,H'}$, then $H' \vDash V : \Gamma$.
\end{corollary}

\begin{proof}
Follows from Lemma $\ref{itm:stable}$.
\end{proof}

% copy

\begin{lemma}[stability of copying]
	Let $H',v' = copy(H,L,v)$. For all $l \in H$, if $l \notin L$, then $H(l) = H'(l)$. 
	Further, $reach_{H'}(v') \subseteq L$.
\end{lemma}

\begin{lemma}[copy is copy]
	Let $H',v' = copy(H,L,v)$. If $H \vDash v \mapsto a : A$, then $H' \vDash v' \mapsto a : A$.
\end{lemma}


%------------------------------------------------------------------------------
% Index
%\printindex

%------------------------------------------------------------------------------
\end{document}


%%% Local Variables:
%%% mode: latex
%%% mode: flyspell
%%% TeX-master: t
%%% End:
